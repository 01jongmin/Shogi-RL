2022-04-22 01:29:00,519	WARNING trial_runner.py:287 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (140 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent trials.
2022-04-22 01:29:00,723	INFO trial_runner.py:803 -- starting DQN_shogi_96499_00000
[2m[36m(DQNTrainer pid=612604)[0m 2022-04-22 01:29:03,195	INFO trainer.py:864 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(RolloutWorker pid=612788)[0m 2022-04-22 01:29:06,818	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612788)[0m 2022-04-22 01:29:06,818	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612790)[0m 2022-04-22 01:29:06,849	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612790)[0m 2022-04-22 01:29:06,849	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612782)[0m 2022-04-22 01:29:06,886	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612782)[0m 2022-04-22 01:29:06,886	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612793)[0m 2022-04-22 01:29:06,911	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612793)[0m 2022-04-22 01:29:06,912	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612781)[0m 2022-04-22 01:29:06,947	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612781)[0m 2022-04-22 01:29:06,947	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612797)[0m 2022-04-22 01:29:06,945	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612797)[0m 2022-04-22 01:29:06,946	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612786)[0m 2022-04-22 01:29:07,018	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612786)[0m 2022-04-22 01:29:07,018	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612794)[0m 2022-04-22 01:29:07,027	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612794)[0m 2022-04-22 01:29:07,027	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612798)[0m 2022-04-22 01:29:06,981	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612798)[0m 2022-04-22 01:29:06,981	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612807)[0m 2022-04-22 01:29:07,045	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612807)[0m 2022-04-22 01:29:07,045	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612826)[0m 2022-04-22 01:29:07,024	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612826)[0m 2022-04-22 01:29:07,025	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(DQNTrainer pid=612604)[0m 2022-04-22 01:29:07,132	WARNING util.py:60 -- Install gputil for GPU system monitoring.
[2m[36m(RolloutWorker pid=612785)[0m 2022-04-22 01:29:07,070	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612785)[0m 2022-04-22 01:29:07,070	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612811)[0m 2022-04-22 01:29:07,096	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612811)[0m 2022-04-22 01:29:07,096	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612815)[0m 2022-04-22 01:29:07,198	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612815)[0m 2022-04-22 01:29:07,199	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612821)[0m 2022-04-22 01:29:07,202	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612821)[0m 2022-04-22 01:29:07,202	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612801)[0m 2022-04-22 01:29:07,253	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612801)[0m 2022-04-22 01:29:07,253	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612805)[0m 2022-04-22 01:29:07,246	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612805)[0m 2022-04-22 01:29:07,247	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612802)[0m 2022-04-22 01:29:07,295	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612802)[0m 2022-04-22 01:29:07,295	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612809)[0m 2022-04-22 01:29:07,280	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612809)[0m 2022-04-22 01:29:07,280	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612813)[0m 2022-04-22 01:29:07,257	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612813)[0m 2022-04-22 01:29:07,257	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612824)[0m 2022-04-22 01:29:07,236	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612824)[0m 2022-04-22 01:29:07,236	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612829)[0m 2022-04-22 01:29:07,221	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612829)[0m 2022-04-22 01:29:07,222	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612840)[0m 2022-04-22 01:29:07,257	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612840)[0m 2022-04-22 01:29:07,257	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612844)[0m 2022-04-22 01:29:07,338	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612844)[0m 2022-04-22 01:29:07,338	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612817)[0m 2022-04-22 01:29:07,377	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612817)[0m 2022-04-22 01:29:07,377	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612822)[0m 2022-04-22 01:29:07,367	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612822)[0m 2022-04-22 01:29:07,368	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612831)[0m 2022-04-22 01:29:07,467	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612831)[0m 2022-04-22 01:29:07,467	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612833)[0m 2022-04-22 01:29:07,396	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612833)[0m 2022-04-22 01:29:07,396	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612834)[0m 2022-04-22 01:29:07,433	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612834)[0m 2022-04-22 01:29:07,433	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612855)[0m 2022-04-22 01:29:07,434	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612855)[0m 2022-04-22 01:29:07,434	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612846)[0m 2022-04-22 01:29:07,503	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612846)[0m 2022-04-22 01:29:07,503	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612858)[0m 2022-04-22 01:29:07,513	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612858)[0m 2022-04-22 01:29:07,513	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612842)[0m 2022-04-22 01:29:07,573	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612842)[0m 2022-04-22 01:29:07,573	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612836)[0m 2022-04-22 01:29:07,546	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612836)[0m 2022-04-22 01:29:07,546	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612838)[0m 2022-04-22 01:29:07,572	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612838)[0m 2022-04-22 01:29:07,573	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612861)[0m 2022-04-22 01:29:07,574	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612861)[0m 2022-04-22 01:29:07,574	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612895)[0m 2022-04-22 01:29:07,590	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612895)[0m 2022-04-22 01:29:07,590	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612914)[0m 2022-04-22 01:29:07,597	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612914)[0m 2022-04-22 01:29:07,597	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612849)[0m 2022-04-22 01:29:07,606	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612849)[0m 2022-04-22 01:29:07,606	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612867)[0m 2022-04-22 01:29:07,606	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612867)[0m 2022-04-22 01:29:07,606	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612854)[0m 2022-04-22 01:29:07,671	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612854)[0m 2022-04-22 01:29:07,671	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612876)[0m 2022-04-22 01:29:07,680	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612876)[0m 2022-04-22 01:29:07,680	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612890)[0m 2022-04-22 01:29:07,668	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612890)[0m 2022-04-22 01:29:07,668	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612893)[0m 2022-04-22 01:29:07,710	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612893)[0m 2022-04-22 01:29:07,710	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612907)[0m 2022-04-22 01:29:07,741	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612907)[0m 2022-04-22 01:29:07,741	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612916)[0m 2022-04-22 01:29:07,738	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612916)[0m 2022-04-22 01:29:07,738	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612872)[0m 2022-04-22 01:29:07,764	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612872)[0m 2022-04-22 01:29:07,764	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612868)[0m 2022-04-22 01:29:07,850	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612868)[0m 2022-04-22 01:29:07,850	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612887)[0m 2022-04-22 01:29:07,855	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612887)[0m 2022-04-22 01:29:07,855	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612884)[0m 2022-04-22 01:29:07,840	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612884)[0m 2022-04-22 01:29:07,840	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612904)[0m 2022-04-22 01:29:07,808	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612904)[0m 2022-04-22 01:29:07,808	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612912)[0m 2022-04-22 01:29:07,809	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612912)[0m 2022-04-22 01:29:07,810	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612953)[0m 2022-04-22 01:29:07,806	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612953)[0m 2022-04-22 01:29:07,806	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613086)[0m 2022-04-22 01:29:07,827	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613086)[0m 2022-04-22 01:29:07,827	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612882)[0m 2022-04-22 01:29:07,869	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612882)[0m 2022-04-22 01:29:07,869	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612879)[0m 2022-04-22 01:29:07,874	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612879)[0m 2022-04-22 01:29:07,874	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612899)[0m 2022-04-22 01:29:07,868	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612899)[0m 2022-04-22 01:29:07,868	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613257)[0m 2022-04-22 01:29:07,896	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613257)[0m 2022-04-22 01:29:07,896	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612932)[0m 2022-04-22 01:29:07,921	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612932)[0m 2022-04-22 01:29:07,922	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613142)[0m 2022-04-22 01:29:07,911	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613142)[0m 2022-04-22 01:29:07,911	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612902)[0m 2022-04-22 01:29:07,912	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612902)[0m 2022-04-22 01:29:07,913	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612978)[0m 2022-04-22 01:29:07,981	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612978)[0m 2022-04-22 01:29:07,981	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613112)[0m 2022-04-22 01:29:07,961	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613112)[0m 2022-04-22 01:29:07,961	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613017)[0m 2022-04-22 01:29:07,988	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613017)[0m 2022-04-22 01:29:07,988	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613056)[0m 2022-04-22 01:29:08,001	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613056)[0m 2022-04-22 01:29:08,001	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612920)[0m 2022-04-22 01:29:08,047	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612920)[0m 2022-04-22 01:29:08,048	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613003)[0m 2022-04-22 01:29:08,099	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613003)[0m 2022-04-22 01:29:08,099	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=612972)[0m 2022-04-22 01:29:08,077	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=612972)[0m 2022-04-22 01:29:08,077	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613295)[0m 2022-04-22 01:29:08,055	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613295)[0m 2022-04-22 01:29:08,055	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613314)[0m 2022-04-22 01:29:08,078	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613314)[0m 2022-04-22 01:29:08,078	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613406)[0m 2022-04-22 01:29:08,053	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613406)[0m 2022-04-22 01:29:08,053	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613466)[0m 2022-04-22 01:29:08,069	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613466)[0m 2022-04-22 01:29:08,069	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613483)[0m 2022-04-22 01:29:08,099	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613483)[0m 2022-04-22 01:29:08,100	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613222)[0m 2022-04-22 01:29:08,116	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613222)[0m 2022-04-22 01:29:08,116	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613105)[0m 2022-04-22 01:29:08,172	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613105)[0m 2022-04-22 01:29:08,172	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613200)[0m 2022-04-22 01:29:08,211	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613200)[0m 2022-04-22 01:29:08,211	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613350)[0m 2022-04-22 01:29:08,216	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613350)[0m 2022-04-22 01:29:08,217	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613563)[0m 2022-04-22 01:29:08,199	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613563)[0m 2022-04-22 01:29:08,199	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613340)[0m 2022-04-22 01:29:08,197	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613340)[0m 2022-04-22 01:29:08,198	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613522)[0m 2022-04-22 01:29:08,187	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613522)[0m 2022-04-22 01:29:08,187	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613670)[0m 2022-04-22 01:29:08,171	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613670)[0m 2022-04-22 01:29:08,171	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613746)[0m 2022-04-22 01:29:08,174	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613746)[0m 2022-04-22 01:29:08,174	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613700)[0m 2022-04-22 01:29:08,176	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613700)[0m 2022-04-22 01:29:08,176	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613634)[0m 2022-04-22 01:29:08,247	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613634)[0m 2022-04-22 01:29:08,247	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613749)[0m 2022-04-22 01:29:08,246	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613749)[0m 2022-04-22 01:29:08,246	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613379)[0m 2022-04-22 01:29:08,296	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613379)[0m 2022-04-22 01:29:08,297	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613784)[0m 2022-04-22 01:29:08,332	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613784)[0m 2022-04-22 01:29:08,332	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613839)[0m 2022-04-22 01:29:08,341	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613839)[0m 2022-04-22 01:29:08,341	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=614075)[0m 2022-04-22 01:29:08,346	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=614075)[0m 2022-04-22 01:29:08,346	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613942)[0m 2022-04-22 01:29:08,353	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613942)[0m 2022-04-22 01:29:08,353	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613570)[0m 2022-04-22 01:29:08,433	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613570)[0m 2022-04-22 01:29:08,433	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613578)[0m 2022-04-22 01:29:08,441	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613578)[0m 2022-04-22 01:29:08,441	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613623)[0m 2022-04-22 01:29:08,401	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613623)[0m 2022-04-22 01:29:08,401	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613736)[0m 2022-04-22 01:29:08,405	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613736)[0m 2022-04-22 01:29:08,405	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613903)[0m 2022-04-22 01:29:08,422	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613903)[0m 2022-04-22 01:29:08,422	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613997)[0m 2022-04-22 01:29:08,412	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613997)[0m 2022-04-22 01:29:08,412	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613812)[0m 2022-04-22 01:29:08,425	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613812)[0m 2022-04-22 01:29:08,426	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613967)[0m 2022-04-22 01:29:08,396	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613967)[0m 2022-04-22 01:29:08,396	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613881)[0m 2022-04-22 01:29:08,434	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613881)[0m 2022-04-22 01:29:08,434	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=614027)[0m 2022-04-22 01:29:08,410	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=614027)[0m 2022-04-22 01:29:08,410	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613928)[0m 2022-04-22 01:29:08,479	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613928)[0m 2022-04-22 01:29:08,479	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=614215)[0m 2022-04-22 01:29:08,452	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=614215)[0m 2022-04-22 01:29:08,452	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=613499)[0m 2022-04-22 01:29:08,473	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=613499)[0m 2022-04-22 01:29:08,473	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=614168)[0m 2022-04-22 01:29:08,493	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=614168)[0m 2022-04-22 01:29:08,493	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=614061)[0m 2022-04-22 01:29:08,500	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=614061)[0m 2022-04-22 01:29:08,500	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=614103)[0m 2022-04-22 01:29:08,586	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=614103)[0m 2022-04-22 01:29:08,586	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=614149)[0m 2022-04-22 01:29:08,515	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
[2m[36m(RolloutWorker pid=614149)[0m 2022-04-22 01:29:08,515	WARNING env.py:40 -- Skipping env checking for this experiment
[2m[36m(RolloutWorker pid=614280)[0m 2022-04-22 01:29:08,625	WARNING rollout_worker.py:498 -- We've added a module for checking environments that are used in experiments. It will cause your environment to fail if your environment is not set upcorrectly. You can disable check env by setting `disable_env_checking` to True in your experiment config dictionary. You can run the environment checking module standalone by calling ray.rllib.utils.check_env(env).
== Status ==
Current time: 2022-04-22 01:29:07 (running for 00:00:06.63)
Memory usage on this node: 22.2/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+
| Trial name            | status   | loc               |
|-----------------------+----------+-------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |
+-----------------------+----------+-------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 1217
  custom_metrics: {}
  date: 2022-04-22_01-29-09
  done: false
  episode_len_mean: 7.1625
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 80
  episodes_total: 80
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 1320
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.18033289909362793
          max_q: 0.05319087952375412
          mean_q: -0.01511147990822792
          min_q: -0.096937395632267
        mean_td_error: 0.06492121517658234
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -0.030639369040727615
        - -0.14049682021141052
        - -0.038656946271657944
        - -0.09921006858348846
        - -0.10978689044713974
        - 0.02588317170739174
        - -0.10796412825584412
        - 1.0309020280838013
        - -0.008138280361890793
        - -0.08375921845436096
        - -0.030639369040727615
        - 0.954562246799469
        - -0.13413922488689423
        - -0.10175683349370956
        - -0.07191107422113419
        - -0.10175683349370956
        - -0.9821600317955017
        - 0.9030625820159912
        - -0.08095867931842804
        - -0.022045236080884933
        - -0.029696621000766754
        - 0.9644589424133301
        - -0.11056997627019882
        - -0.0701950415968895
        - 0.9707112908363342
        - -0.08891066163778305
        - -0.030639369040727615
        - -0.058164697140455246
        - -0.07216105610132217
        - -0.047839850187301636
        - -0.06631216406822205
        - -0.05359288677573204
    num_agent_steps_sampled: 1217
    num_agent_steps_trained: 64
    num_steps_sampled: 1320
    num_steps_trained: 32
    num_steps_trained_this_iter: 32
    num_target_updates: 1
  iterations_since_restore: 1
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 48.36666666666667
    ram_util_percent: 18.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: 0.0
    player_1: 0.0
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.1332530608543983
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6642020665682279
    mean_inference_ms: 1.182992412493779
    mean_raw_obs_processing_ms: 0.4627395134705763
  time_since_restore: 2.024038553237915
  time_this_iter_s: 2.024038553237915
  time_total_s: 2.024038553237915
  timers:
    learn_throughput: 1223.877
    learn_time_ms: 26.146
    update_time_ms: 21.833
  timestamp: 1650590949
  timesteps_since_restore: 32
  timesteps_this_iter: 32
  timesteps_total: 1320
  training_iteration: 1
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:29:09 (running for 00:00:08.70)
Memory usage on this node: 24.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |      1 |          2.02404 | 1320 |        0 |                    0 |                    0 |             7.1625 |
+-----------------------+----------+-------------------+--------+------------------+------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 18377
  custom_metrics: {}
  date: 2022-04-22_01-29-15
  done: false
  episode_len_mean: 12.151898734177216
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 316
  episodes_total: 1554
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 18040
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 0.4098327159881592
          max_q: 6.308981895446777
          mean_q: 1.762322187423706
          min_q: 0.4184783101081848
        mean_td_error: 0.18237684667110443
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -0.7247600555419922
        - -0.08974164724349976
        - -0.6891599893569946
        - -0.6054731011390686
        - -0.8788015842437744
        - -0.8484137058258057
        - -0.02199321985244751
        - -0.0894627571105957
        - -0.021901369094848633
        - -0.5198489427566528
        - 0.6564934253692627
        - 1.6259582042694092
        - -0.5169373750686646
        - -0.9917693138122559
        - -0.497204065322876
        - 2.3414430618286133
        - 4.622092247009277
        - -0.052200913429260254
        - 4.402453422546387
        - 3.307654857635498
        - -1.6287109851837158
        - -0.5700204372406006
        - -0.08589202165603638
        - -0.37136662006378174
        - -0.504727840423584
        - -1.6278845071792603
        - -0.5648746490478516
        - -0.2671867609024048
        - 0.26890528202056885
        - 1.9818997383117676
        - -0.764096736907959
        - -0.4384129047393799
    num_agent_steps_sampled: 18377
    num_agent_steps_trained: 2560
    num_steps_sampled: 18480
    num_steps_trained: 1280
    num_steps_trained_this_iter: 32
    num_target_updates: 20
  iterations_since_restore: 6
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.75
    ram_util_percent: 20.0
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: 0.12974683544303797
    player_1: -0.12974683544303797
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08840934050394779
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6484717039140134
    mean_inference_ms: 1.2142388626534648
    mean_raw_obs_processing_ms: 0.40475446788052677
  time_since_restore: 7.9996278285980225
  time_this_iter_s: 1.3878920078277588
  time_total_s: 7.9996278285980225
  timers:
    learn_throughput: 1561.745
    learn_time_ms: 20.49
    update_time_ms: 16.113
  timestamp: 1650590955
  timesteps_since_restore: 192
  timesteps_this_iter: 32
  timesteps_total: 18480
  training_iteration: 6
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:29:15 (running for 00:00:15.02)
Memory usage on this node: 25.1/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |      6 |          7.99963 | 18480 |        0 |                    0 |                    0 |            12.1519 |
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 34214
  custom_metrics: {}
  date: 2022-04-22_01-29-21
  done: false
  episode_len_mean: 12.220238095238095
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 168
  episodes_total: 2773
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 33880
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 21.5760555267334
          max_q: 367.2935485839844
          mean_q: 139.75808715820312
          min_q: 18.544544219970703
        mean_td_error: 20.40203285217285
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -15.763839721679688
        - -5.1757965087890625
        - 12.46063232421875
        - -56.20530700683594
        - 19.544544219970703
        - -33.423858642578125
        - -28.09746551513672
        - 161.33758544921875
        - -22.4088134765625
        - 100.6134033203125
        - 156.31964111328125
        - -12.360687255859375
        - -40.12133026123047
        - -36.092926025390625
        - -27.503833770751953
        - 61.6806526184082
        - 1.777252197265625
        - -38.36070251464844
        - 201.18344116210938
        - -29.025604248046875
        - -29.588375091552734
        - -102.01286315917969
        - 246.485107421875
        - 16.032135009765625
        - -20.670021057128906
        - -33.499603271484375
        - 21.07977294921875
        - -69.68565368652344
        - 137.38638305664062
        - -36.959259033203125
        - 193.91006469726562
        - -39.9896240234375
    num_agent_steps_sampled: 34214
    num_agent_steps_trained: 4864
    num_steps_sampled: 34320
    num_steps_trained: 2432
    num_steps_trained_this_iter: 32
    num_target_updates: 38
  iterations_since_restore: 11
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.1
    ram_util_percent: 20.2
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.36904761904761907
    player_1: 0.36904761904761907
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08574107747706906
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6406852938931917
    mean_inference_ms: 1.1998499326649348
    mean_raw_obs_processing_ms: 0.3977834035794195
  time_since_restore: 13.561424255371094
  time_this_iter_s: 0.9920151233673096
  time_total_s: 13.561424255371094
  timers:
    learn_throughput: 1577.234
    learn_time_ms: 20.289
    update_time_ms: 19.614
  timestamp: 1650590961
  timesteps_since_restore: 352
  timesteps_this_iter: 32
  timesteps_total: 34320
  training_iteration: 11
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:29:21 (running for 00:00:20.89)
Memory usage on this node: 25.3/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     11 |          13.5614 | 34320 |        0 |                    0 |                    0 |            12.2202 |
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 48737
  custom_metrics: {}
  date: 2022-04-22_01-29-26
  done: false
  episode_len_mean: 16.103174603174605
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 252
  episodes_total: 3675
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 48840
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 197.88278198242188
          max_q: 11970.56640625
          mean_q: 2691.20703125
          min_q: 433.2370300292969
        mean_td_error: 905.9544067382812
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -788.9418334960938
        - 11969.56640625
        - -617.982177734375
        - -436.572509765625
        - -673.6683349609375
        - 1781.83251953125
        - 1732.958984375
        - 333.11962890625
        - -427.15032958984375
        - -438.85205078125
        - -790.645263671875
        - 4146.08251953125
        - -617.982177734375
        - 1548.775634765625
        - -1403.00048828125
        - 1591.0804443359375
        - 1206.8568115234375
        - 1591.0804443359375
        - -999.6348266601562
        - -429.462646484375
        - -414.4677734375
        - 3155.642333984375
        - -427.15032958984375
        - 1568.7279052734375
        - 121.5185546875
        - 54.987548828125
        - -436.70751953125
        - -211.5103759765625
        - 3446.257568359375
        - 2277.16943359375
        - 1807.215576171875
        - -228.60205078125
    num_agent_steps_sampled: 48737
    num_agent_steps_trained: 6976
    num_steps_sampled: 48840
    num_steps_trained: 3488
    num_steps_trained_this_iter: 32
    num_target_updates: 55
  iterations_since_restore: 15
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.9
    ram_util_percent: 20.3
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.373015873015873
    player_1: 0.373015873015873
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08511195022068667
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6370381788495647
    mean_inference_ms: 1.191132147724199
    mean_raw_obs_processing_ms: 0.3914757741843398
  time_since_restore: 18.733426809310913
  time_this_iter_s: 1.2950093746185303
  time_total_s: 18.733426809310913
  timers:
    learn_throughput: 1550.043
    learn_time_ms: 20.645
    update_time_ms: 18.523
  timestamp: 1650590966
  timesteps_since_restore: 480
  timesteps_this_iter: 32
  timesteps_total: 48840
  training_iteration: 15
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:29:26 (running for 00:00:26.37)
Memory usage on this node: 25.4/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     15 |          18.7334 | 48840 |        0 |                    0 |                    0 |            16.1032 |
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 64574
  custom_metrics: {}
  date: 2022-04-22_01-29-32
  done: false
  episode_len_mean: 14.584905660377359
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 159
  episodes_total: 4638
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 64680
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 592.3809814453125
          max_q: 37853.3828125
          mean_q: 11976.3623046875
          min_q: 2083.1259765625
        mean_td_error: -370.4737548828125
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -1650.095703125
        - -19248.44921875
        - -4603.9208984375
        - -2570.993408203125
        - -4603.9208984375
        - -36471.8046875
        - -2567.461669921875
        - -6087.8017578125
        - -3437.3388671875
        - 14531.3955078125
        - 27633.78125
        - -6087.8017578125
        - -3919.48095703125
        - -869.33984375
        - -3917.4443359375
        - 8478.1396484375
        - -2100.2265625
        - -667.51953125
        - -2344.46142578125
        - -3919.48095703125
        - 11680.05859375
        - 26630.9375
        - 19491.37109375
        - 8479.1572265625
        - -3352.333984375
        - -31914.236328125
        - -6134.6494140625
        - -4603.9208984375
        - -3983.83642578125
        - 34826.3125
        - -5982.333984375
        - -2567.461669921875
    num_agent_steps_sampled: 64574
    num_agent_steps_trained: 9280
    num_steps_sampled: 64680
    num_steps_trained: 4640
    num_steps_trained_this_iter: 32
    num_target_updates: 73
  iterations_since_restore: 20
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.7
    ram_util_percent: 20.3
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.20125786163522014
    player_1: 0.20125786163522014
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08576171712393392
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6430064047984606
    mean_inference_ms: 1.1992935841518175
    mean_raw_obs_processing_ms: 0.39030147364343964
  time_since_restore: 24.534960985183716
  time_this_iter_s: 1.1100785732269287
  time_total_s: 24.534960985183716
  timers:
    learn_throughput: 1535.649
    learn_time_ms: 20.838
    update_time_ms: 19.293
  timestamp: 1650590972
  timesteps_since_restore: 640
  timesteps_this_iter: 32
  timesteps_total: 64680
  training_iteration: 20
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:29:32 (running for 00:00:32.47)
Memory usage on this node: 25.5/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     20 |           24.535 | 64680 |        0 |                    0 |                    0 |            14.5849 |
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 81738
  custom_metrics: {}
  date: 2022-04-22_01-29-39
  done: false
  episode_len_mean: 15.05952380952381
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 252
  episodes_total: 5759
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 81400
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1385.5091552734375
          max_q: 344712.125
          mean_q: 85477.0859375
          min_q: 6124.2802734375
        mean_td_error: 33142.953125
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 344711.125
        - -14281.17578125
        - 22892.67578125
        - -21775.140625
        - -17329.734375
        - -21407.65625
        - -80056.46875
        - -19318.90625
        - 258512.4375
        - 126306.625
        - -27663.08984375
        - 119334.421875
        - -29311.9296875
        - -23191.59375
        - -21174.228515625
        - 43680.60546875
        - -37566.2421875
        - -8543.60546875
        - 254990.3125
        - -18339.14453125
        - -14245.76953125
        - -23871.0
        - -140528.0
        - -15062.3515625
        - -47714.26171875
        - 73176.40625
        - 123956.15625
        - 112636.1875
        - 46272.9921875
        - -11050.2265625
        - 139873.875
        - -13338.7919921875
    num_agent_steps_sampled: 81738
    num_agent_steps_trained: 11776
    num_steps_sampled: 81840
    num_steps_trained: 5888
    num_steps_trained_this_iter: 32
    num_target_updates: 92
  iterations_since_restore: 25
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.05
    ram_util_percent: 20.4
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.28174603174603174
    player_1: 0.28174603174603174
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.0845751734959428
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6369979437184663
    mean_inference_ms: 1.1899856366935446
    mean_raw_obs_processing_ms: 0.38816206394527575
  time_since_restore: 30.747156381607056
  time_this_iter_s: 1.5683231353759766
  time_total_s: 30.747156381607056
  timers:
    learn_throughput: 1553.615
    learn_time_ms: 20.597
    update_time_ms: 19.361
  timestamp: 1650590979
  timesteps_since_restore: 800
  timesteps_this_iter: 32
  timesteps_total: 81840
  training_iteration: 25
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:29:39 (running for 00:00:39.08)
Memory usage on this node: 25.6/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     25 |          30.7472 | 81840 |        0 |                    0 |                    0 |            15.0595 |
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 96259
  custom_metrics: {}
  date: 2022-04-22_01-29-44
  done: false
  episode_len_mean: 17.03913043478261
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 230
  episodes_total: 6664
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 96360
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4767.630859375
          max_q: 773406.1875
          mean_q: 129560.0234375
          min_q: 1056.345703125
        mean_td_error: -17759.244140625
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -201149.125
        - 68274.171875
        - -178740.203125
        - -22056.5
        - -164160.78125
        - 75339.7578125
        - 133495.96875
        - -31967.845703125
        - -85464.71875
        - -67160.78125
        - 31976.453125
        - -26732.4296875
        - -73078.390625
        - 392640.875
        - 238393.8125
        - -100295.1875
        - -32245.9375
        - -82613.734375
        - 39453.1953125
        - -125658.671875
        - -146723.671875
        - -418968.1875
        - -80752.9296875
        - -34860.9140625
        - -148941.96875
        - -31962.982421875
        - -85249.875
        - -67955.140625
        - -36095.890625
        - -26578.15234375
        - 24042.1875
        - 697501.875
    num_agent_steps_sampled: 96259
    num_agent_steps_trained: 13888
    num_steps_sampled: 96360
    num_steps_trained: 6944
    num_steps_trained_this_iter: 32
    num_target_updates: 109
  iterations_since_restore: 29
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.8
    ram_util_percent: 20.5
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.2956521739130435
    player_1: 0.2956521739130435
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08439701518697569
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6350262542950794
    mean_inference_ms: 1.1847032327431184
    mean_raw_obs_processing_ms: 0.3850910495880795
  time_since_restore: 35.874398708343506
  time_this_iter_s: 1.3269941806793213
  time_total_s: 35.874398708343506
  timers:
    learn_throughput: 1494.902
    learn_time_ms: 21.406
    update_time_ms: 18.654
  timestamp: 1650590984
  timesteps_since_restore: 928
  timesteps_this_iter: 32
  timesteps_total: 96360
  training_iteration: 29
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:29:45 (running for 00:00:44.58)
Memory usage on this node: 25.7/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     29 |          35.8744 | 96360 |        0 |                    0 |                    0 |            17.0391 |
+-----------------------+----------+-------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 112096
  custom_metrics: {}
  date: 2022-04-22_01-29-51
  done: false
  episode_len_mean: 16.54705882352941
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 170
  episodes_total: 7668
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 112200
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 2537.500732421875
          max_q: 996219.6875
          mean_q: 327153.65625
          min_q: 42164.921875
        mean_td_error: 42068.1875
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -103884.0625
        - -45532.140625
        - -86371.09375
        - -709576.5625
        - 473118.1875
        - -37906.484375
        - -75900.59375
        - 691017.125
        - -132090.28125
        - 332961.9375
        - 463770.96875
        - -58991.03125
        - -69561.21875
        - -37894.21875
        - 683879.875
        - -90205.6796875
        - 113191.8203125
        - -60612.078125
        - -86371.09375
        - -66688.34375
        - -296578.9375
        - 460551.1875
        - 161895.875
        - -62020.828125
        - -45419.0546875
        - 459212.4375
        - -116749.828125
        - -44548.8125
        - -73513.71875
        - -719874.9375
        - 627465.3125
        - -100591.8125
    num_agent_steps_sampled: 112096
    num_agent_steps_trained: 16192
    num_steps_sampled: 112200
    num_steps_trained: 8096
    num_steps_trained_this_iter: 32
    num_target_updates: 127
  iterations_since_restore: 34
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.050000000000001
    ram_util_percent: 20.5
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3
    player_1: 0.3
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08398104271677471
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6309831843656653
    mean_inference_ms: 1.1768110557903841
    mean_raw_obs_processing_ms: 0.3806949547786705
  time_since_restore: 41.67114067077637
  time_this_iter_s: 1.1765377521514893
  time_total_s: 41.67114067077637
  timers:
    learn_throughput: 1611.592
    learn_time_ms: 19.856
    update_time_ms: 18.358
  timestamp: 1650590991
  timesteps_since_restore: 1088
  timesteps_this_iter: 32
  timesteps_total: 112200
  training_iteration: 34
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:29:51 (running for 00:00:50.67)
Memory usage on this node: 25.7/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     34 |          41.6711 | 112200 |        0 |                    0 |                    0 |            16.5471 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 125299
  custom_metrics: {}
  date: 2022-04-22_01-29-56
  done: false
  episode_len_mean: 15.951807228915662
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 166
  episodes_total: 8492
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 125400
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 46652.23046875
          max_q: 2186602.25
          mean_q: 504829.21875
          min_q: 37581.078125
        mean_td_error: 78693.96875
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 3267.5
        - -92129.875
        - -51372.5625
        - -99868.8125
        - -144229.71875
        - -101662.03125
        - -127406.1875
        - 462118.75
        - -101451.0
        - -125442.09375
        - 1257730.0
        - -90018.71875
        - 1154886.0
        - -92163.4375
        - -55046.78125
        - 214353.75
        - -99893.5625
        - -180355.390625
        - 283157.5625
        - -160437.5625
        - -98053.625
        - -160437.5625
        - -190793.875
        - -280614.0
        - 1238729.0
        - -135669.78125
        - -170960.375
        - 284568.90625
        - 88256.921875
        - -93348.125
        - 283157.5625
        - -100663.65625
    num_agent_steps_sampled: 125299
    num_agent_steps_trained: 18112
    num_steps_sampled: 125400
    num_steps_trained: 9056
    num_steps_trained_this_iter: 32
    num_target_updates: 142
  iterations_since_restore: 38
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.05
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.41566265060240964
    player_1: 0.41566265060240964
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08379509132726592
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6320570876789364
    mean_inference_ms: 1.1792404856091259
    mean_raw_obs_processing_ms: 0.3806248779424162
  time_since_restore: 46.38432168960571
  time_this_iter_s: 0.8604991436004639
  time_total_s: 46.38432168960571
  timers:
    learn_throughput: 1589.427
    learn_time_ms: 20.133
    update_time_ms: 20.747
  timestamp: 1650590996
  timesteps_since_restore: 1216
  timesteps_this_iter: 32
  timesteps_total: 125400
  training_iteration: 38
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:29:56 (running for 00:00:55.77)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     38 |          46.3843 | 125400 |        0 |                    0 |                    0 |            15.9518 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 139816
  custom_metrics: {}
  date: 2022-04-22_01-30-01
  done: false
  episode_len_mean: 16.26751592356688
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 157
  episodes_total: 9410
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 139480
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 39736.109375
          max_q: 4586409.0
          mean_q: 1432410.5
          min_q: 65141.2578125
        mean_td_error: 631935.375
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 787629.0
        - -280794.75
        - 550071.5625
        - 2050515.25
        - -1092300.125
        - -318435.25
        - -582732.1875
        - -230124.25
        - 2651164.25
        - -776328.25
        - 1293773.0
        - -268856.4375
        - -110600.125
        - -64688.75
        - 2217780.25
        - -318964.625
        - -196925.5
        - 4405267.0
        - -960812.0
        - 2651164.25
        - 4586408.0
        - -265666.5625
        - -214430.09375
        - -30316.75
        - 1437700.25
        - 3379037.5
        - -247333.0625
        - -214531.125
        - -265564.5
        - 954420.75
        - -213259.25
        - -90333.9765625
    num_agent_steps_sampled: 139816
    num_agent_steps_trained: 20224
    num_steps_sampled: 139920
    num_steps_trained: 10112
    num_steps_trained_this_iter: 32
    num_target_updates: 158
  iterations_since_restore: 42
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.8
    ram_util_percent: 20.5
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.35668789808917195
    player_1: 0.35668789808917195
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.0836259777968784
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6312512632585645
    mean_inference_ms: 1.1756798053180133
    mean_raw_obs_processing_ms: 0.3815079334675564
  time_since_restore: 51.64977788925171
  time_this_iter_s: 0.9410734176635742
  time_total_s: 51.64977788925171
  timers:
    learn_throughput: 1496.121
    learn_time_ms: 21.389
    update_time_ms: 20.38
  timestamp: 1650591001
  timesteps_since_restore: 1344
  timesteps_this_iter: 32
  timesteps_total: 139920
  training_iteration: 42
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:01 (running for 00:01:01.29)
Memory usage on this node: 25.7/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     42 |          51.6498 | 139920 |        0 |                    0 |                    0 |            16.2675 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 153023
  custom_metrics: {}
  date: 2022-04-22_01-30-07
  done: false
  episode_len_mean: 16.401234567901234
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 162
  episodes_total: 10245
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 152680
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 87210.453125
          max_q: 8264619.0
          mean_q: 2664250.5
          min_q: 239053.40625
        mean_td_error: 830613.9375
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -446621.4375
        - -606781.5
        - -618665.0
        - -532074.5
        - -528281.875
        - -259949.25
        - -505330.84375
        - 915063.3125
        - 3436672.0
        - 4194053.0
        - -402840.875
        - 3413722.0
        - -447246.5
        - -427017.25
        - -379425.25
        - 4422084.5
        - -303984.75
        - 2054478.5
        - -393424.25
        - -379425.25
        - -322717.5
        - -527497.125
        - -193990.25
        - 3413722.0
        - 7714091.0
        - -1411725.0
        - 7340488.0
        - -525251.5
        - -261396.25
        - -371408.0
        - -400503.625
        - -79170.0
    num_agent_steps_sampled: 153023
    num_agent_steps_trained: 22144
    num_steps_sampled: 153120
    num_steps_trained: 11072
    num_steps_trained_this_iter: 32
    num_target_updates: 173
  iterations_since_restore: 46
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.75
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3765432098765432
    player_1: 0.3765432098765432
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08342108409083342
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6314539807303843
    mean_inference_ms: 1.1759714611043626
    mean_raw_obs_processing_ms: 0.38121831606938744
  time_since_restore: 56.66734576225281
  time_this_iter_s: 1.1904053688049316
  time_total_s: 56.66734576225281
  timers:
    learn_throughput: 1614.174
    learn_time_ms: 19.824
    update_time_ms: 18.537
  timestamp: 1650591007
  timesteps_since_restore: 1472
  timesteps_this_iter: 32
  timesteps_total: 153120
  training_iteration: 46
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:07 (running for 00:01:06.72)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     46 |          56.6673 | 153120 |        0 |                    0 |                    0 |            16.4012 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 167540
  custom_metrics: {}
  date: 2022-04-22_01-30-12
  done: false
  episode_len_mean: 16.20622568093385
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 257
  episodes_total: 11151
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 167640
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 72281.0625
          max_q: 7958276.5
          mean_q: 3716529.5
          min_q: 415057.4375
        mean_td_error: 840979.875
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 6733217.0
        - -567226.875
        - 1638769.75
        - 2859737.75
        - -359958.0
        - -464763.5
        - -820075.0
        - -584013.25
        - -299516.5
        - 6733217.0
        - -512485.0
        - -359958.0
        - -813769.4375
        - -833306.625
        - -569396.75
        - -434286.0
        - -261529.0
        - 7958275.5
        - -408974.5
        - 2462130.5
        - 1637038.75
        - -410602.75
        - -1826783.75
        - 3115009.5
        - -527928.5
        - -2475276.0
        - 5797357.0
        - -583686.75
        - 2462130.5
        - -581910.375
        - -276476.0
        - -513604.5
    num_agent_steps_sampled: 167540
    num_agent_steps_trained: 24256
    num_steps_sampled: 167640
    num_steps_trained: 12128
    num_steps_trained_this_iter: 32
    num_target_updates: 190
  iterations_since_restore: 50
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.050000000000001
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.22568093385214008
    player_1: 0.22568093385214008
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.083572889321798
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6323368007783766
    mean_inference_ms: 1.17662707024207
    mean_raw_obs_processing_ms: 0.3811595363413762
  time_since_restore: 61.849825859069824
  time_this_iter_s: 1.312549114227295
  time_total_s: 61.849825859069824
  timers:
    learn_throughput: 1556.003
    learn_time_ms: 20.566
    update_time_ms: 18.622
  timestamp: 1650591012
  timesteps_since_restore: 1600
  timesteps_this_iter: 32
  timesteps_total: 167640
  training_iteration: 50
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:12 (running for 00:01:12.14)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     50 |          61.8498 | 167640 |        0 |                    0 |                    0 |            16.2062 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 180732
  custom_metrics: {}
  date: 2022-04-22_01-30-17
  done: false
  episode_len_mean: 16.43030303030303
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 165
  episodes_total: 11948
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 180840
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 149352.484375
          max_q: 21223340.0
          mean_q: 6248142.5
          min_q: 211616.84375
        mean_td_error: 1602885.5
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 2597831.5
        - -898158.0
        - 11340737.0
        - -1319234.0
        - -823456.5
        - -804248.0
        - -870013.0
        - 5838542.5
        - 2330294.0
        - 20987040.0
        - 3905907.0
        - -823749.5
        - -691245.0
        - -476984.0
        - -1289612.625
        - 11340737.0
        - -903646.5
        - -1680708.5
        - 2999999.25
        - -1289612.625
        - -723224.5
        - 3905907.0
        - 2330294.0
        - 2999999.25
        - -874574.0
        - -745015.0
        - -928040.0
        - -1289612.625
        - -745015.0
        - -644449.5
        - -915133.5
        - -549226.625
    num_agent_steps_sampled: 180732
    num_agent_steps_trained: 26176
    num_steps_sampled: 180840
    num_steps_trained: 13088
    num_steps_trained_this_iter: 32
    num_target_updates: 205
  iterations_since_restore: 54
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.0
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.30303030303030304
    player_1: 0.30303030303030304
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08310959222095606
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6301819677564598
    mean_inference_ms: 1.174866274113131
    mean_raw_obs_processing_ms: 0.37868083396251767
  time_since_restore: 66.57732963562012
  time_this_iter_s: 0.8455965518951416
  time_total_s: 66.57732963562012
  timers:
    learn_throughput: 1590.414
    learn_time_ms: 20.121
    update_time_ms: 18.57
  timestamp: 1650591017
  timesteps_since_restore: 1728
  timesteps_this_iter: 32
  timesteps_total: 180840
  training_iteration: 54
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:17 (running for 00:01:17.32)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     54 |          66.5773 | 180840 |        0 |                    0 |                    0 |            16.4303 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 195260
  custom_metrics: {}
  date: 2022-04-22_01-30-23
  done: false
  episode_len_mean: 15.456928838951312
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 267
  episodes_total: 12883
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 194920
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 259627.09375
          max_q: 20696800.0
          mean_q: 8643109.0
          min_q: 1016498.5
        mean_td_error: 2174952.5
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -651989.0
        - -1656196.0
        - 14747609.0
        - -1614926.5
        - -968066.0
        - 7265627.5
        - -1608500.0
        - -1709849.0
        - 6199079.5
        - 7260729.5
        - 13984082.0
        - 13511881.0
        - -1477197.25
        - -818535.0
        - -1679743.0
        - -866688.0
        - -1382601.5
        - -1477197.25
        - -1382050.0
        - -1709849.0
        - -1621978.5
        - -1169561.0
        - 11693045.0
        - -2205397.0
        - -1365074.0
        - 4138096.5
        - 13984082.0
        - -1477197.25
        - 7892071.0
        - -1259612.0
        - -1329642.5
        - -1645971.0
    num_agent_steps_sampled: 195260
    num_agent_steps_trained: 28288
    num_steps_sampled: 195360
    num_steps_trained: 14144
    num_steps_trained_this_iter: 32
    num_target_updates: 221
  iterations_since_restore: 58
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 9.0
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.27715355805243447
    player_1: 0.27715355805243447
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08359531587035798
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.634676604221398
    mean_inference_ms: 1.1815999413761529
    mean_raw_obs_processing_ms: 0.3833356887864241
  time_since_restore: 72.25950956344604
  time_this_iter_s: 1.6969900131225586
  time_total_s: 72.25950956344604
  timers:
    learn_throughput: 1502.572
    learn_time_ms: 21.297
    update_time_ms: 20.63
  timestamp: 1650591023
  timesteps_since_restore: 1856
  timesteps_this_iter: 32
  timesteps_total: 195360
  training_iteration: 58
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:23 (running for 00:01:23.24)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     58 |          72.2595 | 195360 |        0 |                    0 |                    0 |            15.4569 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 208454
  custom_metrics: {}
  date: 2022-04-22_01-30-28
  done: false
  episode_len_mean: 15.491017964071856
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 167
  episodes_total: 13697
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 208120
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 112109.8359375
          max_q: 47299672.0
          mean_q: 11388966.0
          min_q: 1456364.875
        mean_td_error: 3587677.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -3377382.5
        - -3540428.0
        - -1795468.5
        - 11297179.0
        - -1678256.0
        - -912329.0
        - -2039382.625
        - -2642026.0
        - 25239812.0
        - -2490426.0
        - -3271370.0
        - -2340761.5
        - -1755289.0
        - -1396314.0
        - -3377521.0
        - -2368669.0
        - 45775616.0
        - 47299672.0
        - -3225881.0
        - 5928758.0
        - -2644188.0
        - -1536175.0
        - -2340604.25
        - 11297179.0
        - -3229444.5
        - -2039382.625
        - -3540428.0
        - -2039382.625
        - 5926062.0
        - 20645800.0
        - -1797557.0
        - -3225741.0
    num_agent_steps_sampled: 208454
    num_agent_steps_trained: 30208
    num_steps_sampled: 208560
    num_steps_trained: 15104
    num_steps_trained_this_iter: 32
    num_target_updates: 236
  iterations_since_restore: 62
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 5.7
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.25748502994011974
    player_1: 0.25748502994011974
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08324460636574922
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6326285143364471
    mean_inference_ms: 1.1761478486097416
    mean_raw_obs_processing_ms: 0.38174434679915265
  time_since_restore: 77.00874447822571
  time_this_iter_s: 0.8727321624755859
  time_total_s: 77.00874447822571
  timers:
    learn_throughput: 1579.29
    learn_time_ms: 20.262
    update_time_ms: 19.576
  timestamp: 1650591028
  timesteps_since_restore: 1984
  timesteps_this_iter: 32
  timesteps_total: 208560
  training_iteration: 62
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:28 (running for 00:01:28.47)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     62 |          77.0087 | 208560 |        0 |                    0 |                    0 |             15.491 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 224299
  custom_metrics: {}
  date: 2022-04-22_01-30-34
  done: false
  episode_len_mean: 14.691449814126393
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 269
  episodes_total: 14704
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 223960
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 65803.640625
          max_q: 61271936.0
          mean_q: 23514174.0
          min_q: 1984903.125
        mean_td_error: 14192398.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 27733916.0
        - -4639972.0
        - 33878544.0
        - -5378784.0
        - 21994152.0
        - 15265383.0
        - 61271936.0
        - 10505743.0
        - -3306104.0
        - 61271936.0
        - 8012434.0
        - 26933360.0
        - -3306104.0
        - -2720908.5
        - -1711782.0
        - 5878954.5
        - -3870494.0
        - -4150980.0
        - 33792864.0
        - 8015809.0
        - -4150980.0
        - -3222381.5
        - -3222381.5
        - 61271936.0
        - 21994152.0
        - -2270349.0
        - -4337514.0
        - -4387443.5
        - 26933360.0
        - 21991476.0
        - 61271936.0
        - -3185023.0
    num_agent_steps_sampled: 224299
    num_agent_steps_trained: 32512
    num_steps_sampled: 224400
    num_steps_trained: 16256
    num_steps_trained_this_iter: 32
    num_target_updates: 254
  iterations_since_restore: 66
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.75
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.26394052044609667
    player_1: 0.26394052044609667
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08313707386310326
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6313616936048606
    mean_inference_ms: 1.1752713656311227
    mean_raw_obs_processing_ms: 0.3795320816965384
  time_since_restore: 82.7230474948883
  time_this_iter_s: 1.3167269229888916
  time_total_s: 82.7230474948883
  timers:
    learn_throughput: 1574.555
    learn_time_ms: 20.323
    update_time_ms: 20.099
  timestamp: 1650591034
  timesteps_since_restore: 2112
  timesteps_this_iter: 32
  timesteps_total: 224400
  training_iteration: 66
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:34 (running for 00:01:34.42)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     66 |           82.723 | 224400 |        0 |                    0 |                    0 |            14.6914 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 237500
  custom_metrics: {}
  date: 2022-04-22_01-30-40
  done: false
  episode_len_mean: 16.128205128205128
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 156
  episodes_total: 15523
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 237160
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 774828.5
          max_q: 79417872.0
          mean_q: 24487702.0
          min_q: 275173.3125
        mean_td_error: 9130669.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 79417872.0
        - 13655935.0
        - 13655935.0
        - -3780660.0
        - -5133136.0
        - -3620395.0
        - -5617176.0
        - 15109813.0
        - -2741984.0
        - -4998105.5
        - -4611722.0
        - -4279522.0
        - 79417872.0
        - -2649594.0
        - 275174.3125
        - -5617176.0
        - 34226072.0
        - 15113947.0
        - 21376076.0
        - -4324340.0
        - -4998105.5
        - -2738278.0
        - 28556820.0
        - 28552876.0
        - -4186404.0
        - 43926424.0
        - -4313296.0
        - -3070170.0
        - -4568674.0
        - -2322296.0
        - -4598269.0
        - -2934114.0
    num_agent_steps_sampled: 237500
    num_agent_steps_trained: 34432
    num_steps_sampled: 237600
    num_steps_trained: 17216
    num_steps_trained_this_iter: 32
    num_target_updates: 269
  iterations_since_restore: 70
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.266666666666667
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.23717948717948717
    player_1: 0.23717948717948717
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08336723562980261
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6345565498216806
    mean_inference_ms: 1.17990476370896
    mean_raw_obs_processing_ms: 0.3813057368780954
  time_since_restore: 87.7987289428711
  time_this_iter_s: 1.252720832824707
  time_total_s: 87.7987289428711
  timers:
    learn_throughput: 1544.897
    learn_time_ms: 20.713
    update_time_ms: 20.045
  timestamp: 1650591040
  timesteps_since_restore: 2240
  timesteps_this_iter: 32
  timesteps_total: 237600
  training_iteration: 70
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:40 (running for 00:01:40.08)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     70 |          87.7987 | 237600 |        0 |                    0 |                    0 |            16.1282 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 252018
  custom_metrics: {}
  date: 2022-04-22_01-30-45
  done: false
  episode_len_mean: 15.353658536585366
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 246
  episodes_total: 16457
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 252120
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 216482.9375
          max_q: 64288548.0
          mean_q: 24265484.0
          min_q: 3343057.5
        mean_td_error: -1687451.75
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -48748248.0
        - -4365392.0
        - -2694672.0
        - -4814474.0
        - 28156252.0
        - -4145830.0
        - -6568074.5
        - -3707350.0
        - 27814600.0
        - -4814474.0
        - -2704204.0
        - -5098826.0
        - 37607256.0
        - 18009924.0
        - -48748248.0
        - -3707350.0
        - -4688233.5
        - -4843561.0
        - 33165040.0
        - -4963878.0
        - -3576420.0
        - -4743312.0
        - -6568074.5
        - -4845962.0
        - 28424076.0
        - -6756443.0
        - -3576420.0
        - -3392712.0
        - -48748248.0
        - -4003532.0
        - -4361589.0
        - 18009924.0
    num_agent_steps_sampled: 252018
    num_agent_steps_trained: 36544
    num_steps_sampled: 252120
    num_steps_trained: 18272
    num_steps_trained_this_iter: 32
    num_target_updates: 286
  iterations_since_restore: 74
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.15
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.23577235772357724
    player_1: 0.23577235772357724
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08265464190125409
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6292527437931158
    mean_inference_ms: 1.1709201398419806
    mean_raw_obs_processing_ms: 0.37917776176666307
  time_since_restore: 92.97121453285217
  time_this_iter_s: 1.3155202865600586
  time_total_s: 92.97121453285217
  timers:
    learn_throughput: 1599.979
    learn_time_ms: 20.0
    update_time_ms: 19.377
  timestamp: 1650591045
  timesteps_since_restore: 2368
  timesteps_this_iter: 32
  timesteps_total: 252120
  training_iteration: 74
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:46 (running for 00:01:45.49)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     74 |          92.9712 | 252120 |        0 |                    0 |                    0 |            15.3537 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 265217
  custom_metrics: {}
  date: 2022-04-22_01-30-51
  done: false
  episode_len_mean: 15.563953488372093
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 172
  episodes_total: 17285
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 265320
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 508784.59375
          max_q: 97116480.0
          mean_q: 37055296.0
          min_q: 4378392.5
        mean_td_error: 8629400.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -6079750.0
        - -6548024.0
        - -8811478.0
        - 44151816.0
        - -6310062.0
        - 66308440.0
        - -6064288.0
        - -8811478.0
        - -6065764.0
        - 66308440.0
        - -6380972.5
        - -2991876.0
        - -6893022.0
        - -58125496.0
        - 44151816.0
        - 44151816.0
        - 76852528.0
        - -5768376.0
        - -3607186.0
        - -6064288.0
        - -6890770.0
        - -5033520.0
        - -58125496.0
        - -6050788.0
        - 76852528.0
        - -8519720.0
        - -7309512.0
        - -6369779.5
        - -8811478.0
        - 70686096.0
        - -5959904.0
        - 38270356.0
    num_agent_steps_sampled: 265217
    num_agent_steps_trained: 38464
    num_steps_sampled: 265320
    num_steps_trained: 19232
    num_steps_trained_this_iter: 32
    num_target_updates: 301
  iterations_since_restore: 78
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.0
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.38372093023255816
    player_1: 0.38372093023255816
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08291110006762603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6306937461491774
    mean_inference_ms: 1.1719513538492472
    mean_raw_obs_processing_ms: 0.3789278954216664
  time_since_restore: 97.76924800872803
  time_this_iter_s: 0.8458499908447266
  time_total_s: 97.76924800872803
  timers:
    learn_throughput: 1578.386
    learn_time_ms: 20.274
    update_time_ms: 17.962
  timestamp: 1650591051
  timesteps_since_restore: 2496
  timesteps_this_iter: 32
  timesteps_total: 265320
  training_iteration: 78
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:51 (running for 00:01:50.82)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     78 |          97.7692 | 265320 |        0 |                    0 |                    0 |             15.564 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 279739
  custom_metrics: {}
  date: 2022-04-22_01-30-57
  done: false
  episode_len_mean: 18.80921052631579
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 152
  episodes_total: 18178
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 279400
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 147076.25
          max_q: 133110672.0
          mean_q: 53516384.0
          min_q: 5807033.5
        mean_td_error: 14578373.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -10542024.0
        - 91007696.0
        - -8679972.0
        - -8353916.0
        - -12161764.0
        - -12161764.0
        - 96712664.0
        - -8834654.0
        - -7669304.0
        - 105738592.0
        - -8783926.0
        - -7779464.0
        - -11797056.0
        - 36387520.0
        - -8521748.0
        - 105738592.0
        - -7683176.0
        - 91007696.0
        - -73989936.0
        - -10333344.0
        - -8386476.0
        - -10127436.0
        - -8561256.0
        - 91007696.0
        - 36387520.0
        - -12018828.0
        - -8570820.0
        - 53727392.0
        - -8570820.0
        - -12018828.0
        - 33148040.0
        - -8808972.0
    num_agent_steps_sampled: 279739
    num_agent_steps_trained: 40576
    num_steps_sampled: 279840
    num_steps_trained: 20288
    num_steps_trained_this_iter: 32
    num_target_updates: 317
  iterations_since_restore: 82
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.85
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.2236842105263158
    player_1: 0.2236842105263158
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08243279229792182
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.626309397992002
    mean_inference_ms: 1.1643895435057139
    mean_raw_obs_processing_ms: 0.3762543978014131
  time_since_restore: 103.31381726264954
  time_this_iter_s: 1.2120306491851807
  time_total_s: 103.31381726264954
  timers:
    learn_throughput: 1608.615
    learn_time_ms: 19.893
    update_time_ms: 18.7
  timestamp: 1650591057
  timesteps_since_restore: 2624
  timesteps_this_iter: 32
  timesteps_total: 279840
  training_iteration: 82
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:30:57 (running for 00:01:56.60)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     82 |          103.314 | 279840 |        0 |                    0 |                    0 |            18.8092 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 292937
  custom_metrics: {}
  date: 2022-04-22_01-31-02
  done: false
  episode_len_mean: 17.286713286713287
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 143
  episodes_total: 18985
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 292600
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 233264.90625
          max_q: 193646928.0
          mean_q: 54161872.0
          min_q: 7214957.5
        mean_td_error: 2581106.5
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 79969696.0
        - -10899050.0
        - -8036280.0
        - -15732738.0
        - -12127252.0
        - -14912276.0
        - -9044312.0
        - 69533712.0
        - -11754340.0
        - -11754340.0
        - -11758146.0
        - -12133344.0
        - -90287576.0
        - -15967744.0
        - -10256440.0
        - -14912276.0
        - -7694496.0
        - 46884832.0
        - -11754340.0
        - -11623976.0
        - 30477952.0
        - 34421240.0
        - 69533712.0
        - 79969696.0
        - 79969696.0
        - -41751228.0
        - -15732738.0
        - -13916152.0
        - -13196384.0
        - -16873920.0
        - -14269696.0
        - -11776094.0
    num_agent_steps_sampled: 292937
    num_agent_steps_trained: 42496
    num_steps_sampled: 293040
    num_steps_trained: 21248
    num_steps_trained_this_iter: 32
    num_target_updates: 332
  iterations_since_restore: 86
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.65
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.23776223776223776
    player_1: 0.23776223776223776
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.0823818768789177
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.626905845406158
    mean_inference_ms: 1.1655863512644504
    mean_raw_obs_processing_ms: 0.3761655611577663
  time_since_restore: 108.0549943447113
  time_this_iter_s: 0.8570079803466797
  time_total_s: 108.0549943447113
  timers:
    learn_throughput: 1601.6
    learn_time_ms: 19.98
    update_time_ms: 19.846
  timestamp: 1650591062
  timesteps_since_restore: 2752
  timesteps_this_iter: 32
  timesteps_total: 293040
  training_iteration: 86
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:02 (running for 00:02:01.90)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     86 |          108.055 | 293040 |        0 |                    0 |                    0 |            17.2867 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 308777
  custom_metrics: {}
  date: 2022-04-22_01-31-08
  done: false
  episode_len_mean: 14.182156133828997
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 269
  episodes_total: 20007
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 308440
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 157073.4375
          max_q: 387730560.0
          mean_q: 99798864.0
          min_q: 9348505.0
        mean_td_error: 18434270.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -18767172.0
        - 63242108.0
        - -8937120.0
        - -16294811.0
        - 4731936.0
        - -17908152.0
        - -16937072.0
        - -8937120.0
        - 164007504.0
        - 63242108.0
        - 102115728.0
        - -14001274.0
        - -13975698.0
        - -25596832.0
        - -10656328.0
        - -3930704.0
        - -13992234.0
        - 106922664.0
        - 71249096.0
        - -14001274.0
        - 288187520.0
        - 94509280.0
        - -17350880.0
        - 71249096.0
        - -28014704.0
        - -20565312.0
        - -19972352.0
        - -13963560.0
        - -10656328.0
        - -106524464.0
        - -17309888.0
        - -21267112.0
    num_agent_steps_sampled: 308777
    num_agent_steps_trained: 44800
    num_steps_sampled: 308880
    num_steps_trained: 22400
    num_steps_trained_this_iter: 32
    num_target_updates: 350
  iterations_since_restore: 90
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.8
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.31226765799256506
    player_1: 0.31226765799256506
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08236855976717447
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6275830400895155
    mean_inference_ms: 1.1649312129947815
    mean_raw_obs_processing_ms: 0.37704090522176326
  time_since_restore: 113.70499396324158
  time_this_iter_s: 1.351273536682129
  time_total_s: 113.70499396324158
  timers:
    learn_throughput: 1535.407
    learn_time_ms: 20.841
    update_time_ms: 19.259
  timestamp: 1650591068
  timesteps_since_restore: 2880
  timesteps_this_iter: 32
  timesteps_total: 308880
  training_iteration: 90
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:08 (running for 00:02:07.79)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     90 |          113.705 | 308880 |        0 |                    0 |                    0 |            14.1822 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 321979
  custom_metrics: {}
  date: 2022-04-22_01-31-14
  done: false
  episode_len_mean: 16.56441717791411
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 163
  episodes_total: 20819
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 321640
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 2194662.5
          max_q: 360729344.0
          mean_q: 156693568.0
          min_q: 11740686.0
        mean_td_error: 86527520.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -34285344.0
        - -20388362.0
        - -21595616.0
        - 196649584.0
        - -17617628.0
        - 132771120.0
        - -25715952.0
        - 89383216.0
        - -30552928.0
        - 196649584.0
        - 118160568.0
        - 360729344.0
        - -18651792.0
        - -23250416.0
        - -16702032.0
        - -17596440.0
        - 132771120.0
        - -23250416.0
        - -9012928.0
        - -30329568.0
        - 132771120.0
        - 234048608.0
        - 128125624.0
        - 89383216.0
        - 157485024.0
        - 360729344.0
        - 132771120.0
        - 133798912.0
        - -20388362.0
        - -11509504.0
        - 360729344.0
        - 132771120.0
    num_agent_steps_sampled: 321979
    num_agent_steps_trained: 46720
    num_steps_sampled: 322080
    num_steps_trained: 23360
    num_steps_trained_this_iter: 32
    num_target_updates: 365
  iterations_since_restore: 94
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 5.15
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.36809815950920244
    player_1: 0.36809815950920244
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08250658784883068
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6285956273125072
    mean_inference_ms: 1.1659220580172258
    mean_raw_obs_processing_ms: 0.3756546422514535
  time_since_restore: 118.9636025428772
  time_this_iter_s: 1.2852838039398193
  time_total_s: 118.9636025428772
  timers:
    learn_throughput: 1582.842
    learn_time_ms: 20.217
    update_time_ms: 19.988
  timestamp: 1650591074
  timesteps_since_restore: 3008
  timesteps_this_iter: 32
  timesteps_total: 322080
  training_iteration: 94
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:14 (running for 00:02:13.63)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     94 |          118.964 | 322080 |        0 |                    0 |                    0 |            16.5644 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 336495
  custom_metrics: {}
  date: 2022-04-22_01-31-19
  done: false
  episode_len_mean: 15.54054054054054
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 259
  episodes_total: 21747
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 336600
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1744542.375
          max_q: 430461248.0
          mean_q: 146251696.0
          min_q: 14019780.0
        mean_td_error: 33076562.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -11301776.0
        - -26568448.0
        - 281116928.0
        - -31009516.0
        - 430461248.0
        - 151925792.0
        - -30490704.0
        - -9491344.0
        - -88539392.0
        - 102361072.0
        - -20270844.0
        - -20224364.0
        - 151925792.0
        - -16927376.0
        - -5004864.0
        - -26737612.0
        - -5004864.0
        - -26740152.0
        - -24209808.0
        - -20501920.0
        - -40911136.0
        - -7276176.0
        - 94051000.0
        - -20246364.0
        - -14308512.0
        - -26737612.0
        - 232809504.0
        - -17295864.0
        - 188351872.0
        - -16927376.0
        - -31009516.0
        - -36817696.0
    num_agent_steps_sampled: 336495
    num_agent_steps_trained: 48832
    num_steps_sampled: 336600
    num_steps_trained: 24416
    num_steps_trained_this_iter: 32
    num_target_updates: 382
  iterations_since_restore: 98
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.199999999999999
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.29343629343629346
    player_1: 0.29343629343629346
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08209915392959688
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6251649340911374
    mean_inference_ms: 1.1619246828403724
    mean_raw_obs_processing_ms: 0.3746900905406035
  time_since_restore: 124.22024011611938
  time_this_iter_s: 1.3470664024353027
  time_total_s: 124.22024011611938
  timers:
    learn_throughput: 1582.105
    learn_time_ms: 20.226
    update_time_ms: 22.416
  timestamp: 1650591079
  timesteps_since_restore: 3136
  timesteps_this_iter: 32
  timesteps_total: 336600
  training_iteration: 98
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:19 (running for 00:02:19.12)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |     98 |           124.22 | 336600 |        0 |                    0 |                    0 |            15.5405 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 349693
  custom_metrics: {}
  date: 2022-04-22_01-31-24
  done: false
  episode_len_mean: 16.482558139534884
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 172
  episodes_total: 22603
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 349800
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 508864.625
          max_q: 481118144.0
          mean_q: 154025984.0
          min_q: 10936102.0
        mean_td_error: 74396128.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -33597664.0
        - 481118144.0
        - -27693096.0
        - 176191248.0
        - 105334592.0
        - -27693096.0
        - 9948000.0
        - 157487168.0
        - 481118144.0
        - -66493272.0
        - 115603440.0
        - 172682160.0
        - 171090912.0
        - 94594936.0
        - -27647480.0
        - -16808768.0
        - -34381456.0
        - -27693096.0
        - -23906560.0
        - -21203096.0
        - 105334592.0
        - -16808768.0
        - 1191200.0
        - 171090912.0
        - 176191248.0
        - 9948000.0
        - -8035472.0
        - 51337544.0
        - -34659632.0
        - 115603440.0
        - -21250228.0
        - 172682160.0
    num_agent_steps_sampled: 349693
    num_agent_steps_trained: 50752
    num_steps_sampled: 349800
    num_steps_trained: 25376
    num_steps_trained_this_iter: 32
    num_target_updates: 397
  iterations_since_restore: 102
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.85
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.27906976744186046
    player_1: 0.27906976744186046
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08163180678286953
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6215467648258549
    mean_inference_ms: 1.1560869045403566
    mean_raw_obs_processing_ms: 0.3719585725692785
  time_since_restore: 129.01055097579956
  time_this_iter_s: 0.89306640625
  time_total_s: 129.01055097579956
  timers:
    learn_throughput: 1549.896
    learn_time_ms: 20.647
    update_time_ms: 19.529
  timestamp: 1650591084
  timesteps_since_restore: 3264
  timesteps_this_iter: 32
  timesteps_total: 349800
  training_iteration: 102
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:25 (running for 00:02:24.52)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    102 |          129.011 | 349800 |        0 |                    0 |                    0 |            16.4826 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 364219
  custom_metrics: {}
  date: 2022-04-22_01-31-30
  done: false
  episode_len_mean: 16.973856209150327
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 153
  episodes_total: 23499
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 363880
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 378545.59375
          max_q: 647432448.0
          mean_q: 176827408.0
          min_q: 23534396.0
        mean_td_error: 61212392.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 126648160.0
        - 192602080.0
        - -23866944.0
        - 126589224.0
        - -19794736.0
        - -19187288.0
        - 339387520.0
        - -38395824.0
        - -38392272.0
        - 181318544.0
        - 126589224.0
        - -15758128.0
        - -62993216.0
        - -38493896.0
        - -24248808.0
        - 181318544.0
        - 351138528.0
        - 351138528.0
        - -42674816.0
        - -3337472.0
        - -23820416.0
        - -19791280.0
        - -11761984.0
        - -13656544.0
        - -23820416.0
        - 14535174.0
        - -38395824.0
        - -31443880.0
        - 126673456.0
        - 227956528.0
        - 126589224.0
        - -23854628.0
    num_agent_steps_sampled: 364219
    num_agent_steps_trained: 52864
    num_steps_sampled: 364320
    num_steps_trained: 26432
    num_steps_trained_this_iter: 32
    num_target_updates: 413
  iterations_since_restore: 106
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.1
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.26143790849673204
    player_1: 0.26143790849673204
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08152822061391204
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6200520645423997
    mean_inference_ms: 1.1531302210544245
    mean_raw_obs_processing_ms: 0.3706593889952773
  time_since_restore: 134.67096257209778
  time_this_iter_s: 1.2581822872161865
  time_total_s: 134.67096257209778
  timers:
    learn_throughput: 1563.178
    learn_time_ms: 20.471
    update_time_ms: 20.206
  timestamp: 1650591090
  timesteps_since_restore: 3392
  timesteps_this_iter: 32
  timesteps_total: 364320
  training_iteration: 106
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:30 (running for 00:02:30.42)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    106 |          134.671 | 364320 |        0 |                    0 |                    0 |            16.9739 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 377418
  custom_metrics: {}
  date: 2022-04-22_01-31-36
  done: false
  episode_len_mean: 16.928571428571427
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 154
  episodes_total: 24291
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 377080
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1764165.5
          max_q: 766608768.0
          mean_q: 254504256.0
          min_q: 20197302.0
        mean_td_error: 49541720.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 214555312.0
        - -35469376.0
        - -39815392.0
        - 149809920.0
        - 214555312.0
        - -37038648.0
        - -12565184.0
        - 227538272.0
        - 403893504.0
        - -18084292.0
        - -35422872.0
        - -46154624.0
        - -43367744.0
        - -69836352.0
        - 227538272.0
        - -20030736.0
        - -78997376.0
        - -7368000.0
        - -22797432.0
        - -22797432.0
        - 415574784.0
        - -69784288.0
        - 214555312.0
        - -43367744.0
        - 227538272.0
        - -48971904.0
        - -48971904.0
        - -52617920.0
        - -35469376.0
        - 227538272.0
        - -78997376.0
        - -69836352.0
    num_agent_steps_sampled: 377418
    num_agent_steps_trained: 54784
    num_steps_sampled: 377520
    num_steps_trained: 27392
    num_steps_trained_this_iter: 32
    num_target_updates: 428
  iterations_since_restore: 110
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.35
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.33766233766233766
    player_1: 0.33766233766233766
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08197505415437699
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6250590172230875
    mean_inference_ms: 1.1594092818723387
    mean_raw_obs_processing_ms: 0.3749572102557165
  time_since_restore: 139.5701198577881
  time_this_iter_s: 0.9130058288574219
  time_total_s: 139.5701198577881
  timers:
    learn_throughput: 1530.752
    learn_time_ms: 20.905
    update_time_ms: 18.362
  timestamp: 1650591096
  timesteps_since_restore: 3520
  timesteps_this_iter: 32
  timesteps_total: 377520
  training_iteration: 110
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:36 (running for 00:02:35.96)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    110 |           139.57 | 377520 |        0 |                    0 |                    0 |            16.9286 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 393257
  custom_metrics: {}
  date: 2022-04-22_01-31-42
  done: false
  episode_len_mean: 15.568627450980392
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 255
  episodes_total: 25289
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 392920
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 826808.3125
          max_q: 706578688.0
          mean_q: 237915824.0
          min_q: 13560261.0
        mean_td_error: 128507728.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -27011168.0
        - -27028912.0
        - -44923672.0
        - -101106456.0
        - 477761888.0
        - -27078288.0
        - -32431176.0
        - -40356868.0
        - -15989056.0
        - 172500384.0
        - 21450828.0
        - 477761888.0
        - -55911632.0
        - 21450828.0
        - -20838448.0
        - 462132096.0
        - 462132096.0
        - -40423324.0
        - -43433860.0
        - -76009792.0
        - -44941544.0
        - 462132096.0
        - -43218696.0
        - 706578688.0
        - 260625472.0
        - -44334128.0
        - -40423324.0
        - -40356868.0
        - 706578688.0
        - 706578688.0
        - -44334128.0
        - -15284864.0
    num_agent_steps_sampled: 393257
    num_agent_steps_trained: 57088
    num_steps_sampled: 393360
    num_steps_trained: 28544
    num_steps_trained_this_iter: 32
    num_target_updates: 446
  iterations_since_restore: 114
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.45
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3176470588235294
    player_1: 0.3176470588235294
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08207094012807792
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6255659453555609
    mean_inference_ms: 1.1628213544307955
    mean_raw_obs_processing_ms: 0.3738136521836535
  time_since_restore: 145.36729311943054
  time_this_iter_s: 1.317075252532959
  time_total_s: 145.36729311943054
  timers:
    learn_throughput: 1596.809
    learn_time_ms: 20.04
    update_time_ms: 20.113
  timestamp: 1650591102
  timesteps_since_restore: 3648
  timesteps_this_iter: 32
  timesteps_total: 393360
  training_iteration: 114
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:42 (running for 00:02:41.99)
Memory usage on this node: 25.8/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    114 |          145.367 | 393360 |        0 |                    0 |                    0 |            15.5686 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 405138
  custom_metrics: {}
  date: 2022-04-22_01-31-47
  done: false
  episode_len_mean: 15.92
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 91
  episodes_total: 26052
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 405240
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 327423.84375
          max_q: 633882816.0
          mean_q: 267509344.0
          min_q: 27373060.0
        mean_td_error: 116771336.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -52705088.0
        - -37711528.0
        - -45907772.0
        - 213457936.0
        - -68633216.0
        - 532423840.0
        - 160217120.0
        - -56277320.0
        - 133710848.0
        - -57688224.0
        - -49595792.0
        - 213457936.0
        - -11974208.0
        - 30908160.0
        - 200669024.0
        - -31738640.0
        - 633882816.0
        - 532423840.0
        - -24895808.0
        - -24895808.0
        - -31731472.0
        - -18288368.0
        - -18286112.0
        - -72752752.0
        - 633882816.0
        - 633882816.0
        - -37823304.0
        - -56277320.0
        - 633882816.0
        - -31738640.0
        - -31793328.0
        - -55402752.0
    num_agent_steps_sampled: 405138
    num_agent_steps_trained: 58816
    num_steps_sampled: 405240
    num_steps_trained: 29408
    num_steps_trained_this_iter: 32
    num_target_updates: 460
  iterations_since_restore: 118
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 3.2
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.45
    player_1: 0.45
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08118596590295227
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6171641419188378
    mean_inference_ms: 1.147557299599141
    mean_raw_obs_processing_ms: 0.3673912394057753
  time_since_restore: 149.73357105255127
  time_this_iter_s: 0.44302845001220703
  time_total_s: 149.73357105255127
  timers:
    learn_throughput: 1590.082
    learn_time_ms: 20.125
    update_time_ms: 22.714
  timestamp: 1650591107
  timesteps_since_restore: 3776
  timesteps_this_iter: 32
  timesteps_total: 405240
  training_iteration: 118
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:47 (running for 00:02:47.10)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    118 |          149.734 | 405240 |        0 |                    0 |                    0 |              15.92 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 418339
  custom_metrics: {}
  date: 2022-04-22_01-31-53
  done: false
  episode_len_mean: 16.0561797752809
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 178
  episodes_total: 26890
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 418440
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 475448.625
          max_q: 764754048.0
          mean_q: 216517344.0
          min_q: 2321633.0
        mean_td_error: 33732068.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -22175052.0
        - -33283488.0
        - -54333140.0
        - -54333140.0
        - -54353052.0
        - -57490960.0
        - -62241056.0
        - -40249552.0
        - -54353052.0
        - -65456176.0
        - 764754048.0
        - -69905112.0
        - -55530624.0
        - -45436512.0
        - -67264944.0
        - -65456176.0
        - -65456176.0
        - -54420796.0
        - -40269952.0
        - -60041792.0
        - -26930240.0
        - -24203296.0
        - 764754048.0
        - -40353872.0
        - 192679744.0
        - -46366112.0
        - 764754048.0
        - -46537968.0
        - -24203296.0
        - -54420796.0
        - -65456176.0
        - -56993376.0
    num_agent_steps_sampled: 418339
    num_agent_steps_trained: 60736
    num_steps_sampled: 418440
    num_steps_trained: 30368
    num_steps_trained_this_iter: 32
    num_target_updates: 475
  iterations_since_restore: 122
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.15
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.25842696629213485
    player_1: 0.25842696629213485
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08198364951542308
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6254368156168726
    mean_inference_ms: 1.1603933122801575
    mean_raw_obs_processing_ms: 0.3742984090699532
  time_since_restore: 155.00704264640808
  time_this_iter_s: 1.275099754333496
  time_total_s: 155.00704264640808
  timers:
    learn_throughput: 1523.899
    learn_time_ms: 20.999
    update_time_ms: 18.31
  timestamp: 1650591113
  timesteps_since_restore: 3904
  timesteps_this_iter: 32
  timesteps_total: 418440
  training_iteration: 122
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:53 (running for 00:02:52.61)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    122 |          155.007 | 418440 |        0 |                    0 |                    0 |            16.0562 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 431538
  custom_metrics: {}
  date: 2022-04-22_01-31-58
  done: false
  episode_len_mean: 16.935622317596568
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 233
  episodes_total: 27684
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 431640
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 10567261.0
          max_q: 1322971392.0
          mean_q: 451363072.0
          min_q: 8400189.0
        mean_td_error: 172835536.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -77911312.0
        - -84519736.0
        - -65516184.0
        - -9827679.0
        - -65437592.0
        - -86903680.0
        - 1322971392.0
        - 381781728.0
        - -34352912.0
        - 381781728.0
        - -57809376.0
        - -77447936.0
        - -69375296.0
        - -44646528.0
        - 1322971392.0
        - -83131136.0
        - -57413504.0
        - -17956352.0
        - 381781728.0
        - 1322971392.0
        - 152488928.0
        - -72627264.0
        - 1322971392.0
        - -65516184.0
        - -87291136.0
        - -75285376.0
        - -57512624.0
        - -49252144.0
        - 381781728.0
        - -66163008.0
        - -77354880.0
        - -57512624.0
    num_agent_steps_sampled: 431538
    num_agent_steps_trained: 62656
    num_steps_sampled: 431640
    num_steps_trained: 31328
    num_steps_trained_this_iter: 32
    num_target_updates: 490
  iterations_since_restore: 126
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.85
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3261802575107296
    player_1: 0.3261802575107296
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08167285225200488
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6231352172402738
    mean_inference_ms: 1.157212720001113
    mean_raw_obs_processing_ms: 0.3722498138666329
  time_since_restore: 159.98823237419128
  time_this_iter_s: 1.3755745887756348
  time_total_s: 159.98823237419128
  timers:
    learn_throughput: 1518.329
    learn_time_ms: 21.076
    update_time_ms: 20.03
  timestamp: 1650591118
  timesteps_since_restore: 4032
  timesteps_this_iter: 32
  timesteps_total: 431640
  training_iteration: 126
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:31:58 (running for 00:02:58.31)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    126 |          159.988 | 431640 |        0 |                    0 |                    0 |            16.9356 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 443416
  custom_metrics: {}
  date: 2022-04-22_01-32-03
  done: false
  episode_len_mean: 16.663967611336034
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 247
  episodes_total: 28444
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 443080
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 996943.625
          max_q: 1557107712.0
          mean_q: 465122816.0
          min_q: 46048832.0
        mean_td_error: 57197736.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -42452736.0
        - -39159360.0
        - -70106712.0
        - -106942528.0
        - -80782080.0
        - -37092736.0
        - 1557107712.0
        - -64303296.0
        - -69387936.0
        - 430494720.0
        - -60106944.0
        - -87016576.0
        - -76364304.0
        - -65009600.0
        - -106942528.0
        - 1557107712.0
        - -80782080.0
        - -76482384.0
        - -84671232.0
        - -65036992.0
        - -94772864.0
        - -101034432.0
        - -76364304.0
        - -101021008.0
        - -76364304.0
        - -86428224.0
        - -80782080.0
        - -92013376.0
        - -106942528.0
        - 444140896.0
        - -65009600.0
        - -65150560.0
    num_agent_steps_sampled: 443416
    num_agent_steps_trained: 64384
    num_steps_sampled: 443520
    num_steps_trained: 32192
    num_steps_trained_this_iter: 32
    num_target_updates: 503
  iterations_since_restore: 130
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.35
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3319838056680162
    player_1: 0.3319838056680162
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08142819157493282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6219700229132984
    mean_inference_ms: 1.1545049581519657
    mean_raw_obs_processing_ms: 0.37264599197437887
  time_since_restore: 164.3597059249878
  time_this_iter_s: 1.285456895828247
  time_total_s: 164.3597059249878
  timers:
    learn_throughput: 1627.846
    learn_time_ms: 19.658
    update_time_ms: 19.429
  timestamp: 1650591123
  timesteps_since_restore: 4160
  timesteps_this_iter: 32
  timesteps_total: 443520
  training_iteration: 130
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:04 (running for 00:03:04.32)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    131 |           165.71 | 447480 |        0 |                    0 |                    0 |            14.9697 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 457938
  custom_metrics: {}
  date: 2022-04-22_01-32-09
  done: false
  episode_len_mean: 15.535315985130111
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 269
  episodes_total: 29393
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 458040
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 627584.1875
          max_q: 963507008.0
          mean_q: 376892736.0
          min_q: 55186848.0
        mean_td_error: 33648988.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -121550416.0
        - 615783552.0
        - -122371904.0
        - -46138816.0
        - -88944064.0
        - -79904496.0
        - -71615136.0
        - 615783552.0
        - -80004800.0
        - -137221184.0
        - 615783552.0
        - -71583392.0
        - -137221184.0
        - -108029680.0
        - -121550416.0
        - 146006624.0
        - -113682272.0
        - 529208640.0
        - -137221184.0
        - -71615136.0
        - -125468128.0
        - -108029680.0
        - -112516256.0
        - -99465472.0
        - 529208640.0
        - -99465472.0
        - -98081280.0
        - -93840784.0
        - 529208640.0
        - -93840784.0
        - -71012928.0
        - -93840784.0
    num_agent_steps_sampled: 457938
    num_agent_steps_trained: 66496
    num_steps_sampled: 458040
    num_steps_trained: 33248
    num_steps_trained_this_iter: 32
    num_target_updates: 520
  iterations_since_restore: 134
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.866666666666666
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.35315985130111527
    player_1: 0.35315985130111527
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08123139908588084
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.620833045335269
    mean_inference_ms: 1.1527998725537933
    mean_raw_obs_processing_ms: 0.37169976204792915
  time_since_restore: 170.0137004852295
  time_this_iter_s: 1.704519510269165
  time_total_s: 170.0137004852295
  timers:
    learn_throughput: 1572.642
    learn_time_ms: 20.348
    update_time_ms: 18.825
  timestamp: 1650591129
  timesteps_since_restore: 4288
  timesteps_this_iter: 32
  timesteps_total: 458040
  training_iteration: 134
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:10 (running for 00:03:09.79)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    135 |          170.463 | 459360 |        0 |                    0 |                    0 |              15.43 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 469814
  custom_metrics: {}
  date: 2022-04-22_01-32-14
  done: false
  episode_len_mean: 17.092105263157894
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 152
  episodes_total: 30102
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 469480
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 446799.71875
          max_q: 1286401280.0
          mean_q: 498190368.0
          min_q: 63646112.0
        mean_td_error: 139275680.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 432336576.0
        - 930948288.0
        - -160945792.0
        - -83617888.0
        - -152040800.0
        - -112154736.0
        - -126334144.0
        - 622443776.0
        - -55612288.0
        - 622443776.0
        - 930948288.0
        - -152040800.0
        - -112111040.0
        - -45585152.0
        - -174979200.0
        - -152040800.0
        - -112154736.0
        - -138187360.0
        - 930948288.0
        - -152040800.0
        - 930948288.0
        - -114343296.0
        - 432336576.0
        - -144399232.0
        - 930948288.0
        - -152044192.0
        - -112154736.0
        - -114343296.0
        - 382251520.0
        - -112111040.0
        - -81821024.0
        - -128668896.0
    num_agent_steps_sampled: 469814
    num_agent_steps_trained: 68224
    num_steps_sampled: 469920
    num_steps_trained: 34112
    num_steps_trained_this_iter: 32
    num_target_updates: 533
  iterations_since_restore: 138
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 5.9
    ram_util_percent: 20.6
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.48026315789473684
    player_1: 0.48026315789473684
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08134310743307077
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6212001595740345
    mean_inference_ms: 1.1537306598330337
    mean_raw_obs_processing_ms: 0.37187011318823954
  time_since_restore: 174.33588671684265
  time_this_iter_s: 1.2499051094055176
  time_total_s: 174.33588671684265
  timers:
    learn_throughput: 1612.531
    learn_time_ms: 19.845
    update_time_ms: 18.204
  timestamp: 1650591134
  timesteps_since_restore: 4416
  timesteps_this_iter: 32
  timesteps_total: 469920
  training_iteration: 138
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:15 (running for 00:03:15.25)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    139 |          175.687 | 473880 |        0 |                    0 |                    0 |            16.6807 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 483019
  custom_metrics: {}
  date: 2022-04-22_01-32-19
  done: false
  episode_len_mean: 15.061224489795919
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 196
  episodes_total: 30929
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 482680
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 358821.4375
          max_q: 1941271808.0
          mean_q: 744845056.0
          min_q: 70421064.0
        mean_td_error: 441520608.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -131500392.0
        - -13703040.0
        - 1941271808.0
        - 791748480.0
        - 714279808.0
        - -241863296.0
        - 791748480.0
        - 1025873792.0
        - -97479808.0
        - -152610464.0
        - -169010848.0
        - -172061696.0
        - 1941271808.0
        - -131500392.0
        - 421721248.0
        - -108756032.0
        - 714279808.0
        - -70917856.0
        - 1941271808.0
        - -241863296.0
        - 1941271808.0
        - -187224000.0
        - 421721248.0
        - 714279808.0
        - -131450392.0
        - -131500392.0
        - 714279808.0
        - -36828224.0
        - -131450392.0
        - -234631808.0
        - 496720512.0
        - 1941271808.0
    num_agent_steps_sampled: 483019
    num_agent_steps_trained: 70144
    num_steps_sampled: 483120
    num_steps_trained: 35072
    num_steps_trained_this_iter: 32
    num_target_updates: 548
  iterations_since_restore: 142
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.75
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.2193877551020408
    player_1: 0.2193877551020408
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.0816904696104068
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6235145526014563
    mean_inference_ms: 1.1575152239371544
    mean_raw_obs_processing_ms: 0.3720527475954159
  time_since_restore: 179.30890703201294
  time_this_iter_s: 0.9588172435760498
  time_total_s: 179.30890703201294
  timers:
    learn_throughput: 1536.97
    learn_time_ms: 20.82
    update_time_ms: 19.639
  timestamp: 1650591139
  timesteps_since_restore: 4544
  timesteps_this_iter: 32
  timesteps_total: 483120
  training_iteration: 142
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:21 (running for 00:03:21.02)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    143 |          180.667 | 487080 |        0 |                    0 |                    0 |            15.7309 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 497537
  custom_metrics: {}
  date: 2022-04-22_01-32-25
  done: false
  episode_len_mean: 15.66030534351145
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 262
  episodes_total: 31849
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 497640
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 443914.96875
          max_q: 1878175360.0
          mean_q: 816487424.0
          min_q: 78462928.0
        mean_td_error: 267357536.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 460048576.0
        - 1878175360.0
        - -261926976.0
        - -100993184.0
        - -147096560.0
        - -146894976.0
        - 1878175360.0
        - -299961984.0
        - 1878175360.0
        - -270819456.0
        - -185358336.0
        - -213862144.0
        - 860807296.0
        - -250234112.0
        - 860807296.0
        - 587216960.0
        - 1878175360.0
        - -270819456.0
        - -70264416.0
        - -175683840.0
        - -250234112.0
        - -101008624.0
        - 1878175360.0
        - -185358336.0
        - -96382784.0
        - 552643264.0
        - -270819456.0
        - -175665344.0
        - -175665344.0
        - -147096560.0
        - -213862144.0
        - -146951776.0
    num_agent_steps_sampled: 497537
    num_agent_steps_trained: 72256
    num_steps_sampled: 497640
    num_steps_trained: 36128
    num_steps_trained_this_iter: 32
    num_target_updates: 565
  iterations_since_restore: 147
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.399999999999999
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.30916030534351147
    player_1: 0.30916030534351147
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08110521413942988
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6201915691495269
    mean_inference_ms: 1.1505561349342766
    mean_raw_obs_processing_ms: 0.3727854222761856
  time_since_restore: 184.70780992507935
  time_this_iter_s: 1.34293794631958
  time_total_s: 184.70780992507935
  timers:
    learn_throughput: 1555.087
    learn_time_ms: 20.578
    update_time_ms: 20.557
  timestamp: 1650591145
  timesteps_since_restore: 4704
  timesteps_this_iter: 32
  timesteps_total: 497640
  training_iteration: 147
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:27 (running for 00:03:26.71)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    148 |          185.996 | 500280 |        0 |                    0 |                    0 |            14.7877 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 512056
  custom_metrics: {}
  date: 2022-04-22_01-32-31
  done: false
  episode_len_mean: 15.169291338582678
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 254
  episodes_total: 32766
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 511720
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 323665.8125
          max_q: 2026465664.0
          mean_q: 906673152.0
          min_q: 86727840.0
        mean_td_error: 277814848.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 2003111424.0
        - -155065792.0
        - 918151680.0
        - -297567104.0
        - -253754624.0
        - -172593600.0
        - 18554880.0
        - -253754624.0
        - -113250976.0
        - -109017312.0
        - 918151680.0
        - -109017312.0
        - 918151680.0
        - -152027312.0
        - -112925824.0
        - -253754624.0
        - -82808064.0
        - 918151680.0
        - -253754624.0
        - 918151680.0
        - 918151680.0
        - -154881376.0
        - -109017312.0
        - -155065792.0
        - 2003111424.0
        - -175875008.0
        - 2003111424.0
        - 287224096.0
        - -128860096.0
        - -87026624.0
        - 493637408.0
        - -297567104.0
    num_agent_steps_sampled: 512056
    num_agent_steps_trained: 74368
    num_steps_sampled: 512160
    num_steps_trained: 37184
    num_steps_trained_this_iter: 32
    num_target_updates: 581
  iterations_since_restore: 151
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.233333333333333
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.33858267716535434
    player_1: 0.33858267716535434
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08155736119420408
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6228745790006062
    mean_inference_ms: 1.156101301762047
    mean_raw_obs_processing_ms: 0.37217020593209027
  time_since_restore: 190.38317894935608
  time_this_iter_s: 1.7084605693817139
  time_total_s: 190.38317894935608
  timers:
    learn_throughput: 1577.978
    learn_time_ms: 20.279
    update_time_ms: 18.56
  timestamp: 1650591151
  timesteps_since_restore: 4832
  timesteps_this_iter: 32
  timesteps_total: 512160
  training_iteration: 151
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:32 (running for 00:03:31.83)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    151 |          190.383 | 512160 |        0 |                    0 |                    0 |            15.1693 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 523938
  custom_metrics: {}
  date: 2022-04-22_01-32-37
  done: false
  episode_len_mean: 15.775147928994082
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 169
  episodes_total: 33519
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 524040
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 390088.21875
          max_q: 2923917312.0
          mean_q: 568641280.0
          min_q: 89316000.0
        mean_td_error: 66609528.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -170022048.0
        - 90250240.0
        - -93524960.0
        - -93522496.0
        - 578866496.0
        - -89789696.0
        - -149843552.0
        - -225487232.0
        - -149843552.0
        - 920064384.0
        - -170022048.0
        - -203247232.0
        - -115832768.0
        - -158481632.0
        - 904442368.0
        - -124839776.0
        - -149898496.0
        - 920064384.0
        - 287556288.0
        - -149843552.0
        - -274032896.0
        - -149843552.0
        - -158481632.0
        - -170287552.0
        - 904442368.0
        - -149843552.0
        - -170022048.0
        - -124839776.0
        - -149898496.0
        - 496812608.0
        - 578940416.0
        - -158485920.0
    num_agent_steps_sampled: 523938
    num_agent_steps_trained: 76096
    num_steps_sampled: 524040
    num_steps_trained: 38048
    num_steps_trained_this_iter: 32
    num_target_updates: 595
  iterations_since_restore: 155
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.5
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.31952662721893493
    player_1: 0.31952662721893493
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.081389305495465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.621270781990932
    mean_inference_ms: 1.1536367968807946
    mean_raw_obs_processing_ms: 0.37111147353773444
  time_since_restore: 194.88044595718384
  time_this_iter_s: 0.9453485012054443
  time_total_s: 194.88044595718384
  timers:
    learn_throughput: 1544.263
    learn_time_ms: 20.722
    update_time_ms: 19.94
  timestamp: 1650591157
  timesteps_since_restore: 4960
  timesteps_this_iter: 32
  timesteps_total: 524040
  training_iteration: 155
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:38 (running for 00:03:37.58)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    156 |          195.824 | 526680 |        0 |                    0 |                    0 |            15.5535 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 539776
  custom_metrics: {}
  date: 2022-04-22_01-32-43
  done: false
  episode_len_mean: 16.600840336134453
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 238
  episodes_total: 34485
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 539880
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 24521076.0
          max_q: 2496853248.0
          mean_q: 942076288.0
          min_q: 260416672.0
        mean_td_error: 251468352.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 2220965376.0
        - 623825024.0
        - -182092032.0
        - -220758784.0
        - -15043328.0
        - -167987904.0
        - 550548800.0
        - -252602368.0
        - 623825024.0
        - 550548800.0
        - 718260800.0
        - -83645056.0
        - 718260800.0
        - 623825024.0
        - -183929216.0
        - -167987904.0
        - -220758784.0
        - -167923776.0
        - -66073728.0
        - 718260800.0
        - -167923776.0
        - 2220965376.0
        - 623825024.0
        - -118002624.0
        - -252602368.0
        - -182029520.0
        - 448283840.0
        - -220758784.0
        - -115213440.0
        - -177530112.0
        - 550548800.0
        - -182092032.0
    num_agent_steps_sampled: 539776
    num_agent_steps_trained: 78400
    num_steps_sampled: 539880
    num_steps_trained: 39200
    num_steps_trained_this_iter: 32
    num_target_updates: 613
  iterations_since_restore: 160
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.45
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.29411764705882354
    player_1: 0.29411764705882354
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08140163476026625
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6217856991536354
    mean_inference_ms: 1.1547978924338451
    mean_raw_obs_processing_ms: 0.37116936469207806
  time_since_restore: 200.76132535934448
  time_this_iter_s: 1.3781976699829102
  time_total_s: 200.76132535934448
  timers:
    learn_throughput: 1548.112
    learn_time_ms: 20.67
    update_time_ms: 22.171
  timestamp: 1650591163
  timesteps_since_restore: 5120
  timesteps_this_iter: 32
  timesteps_total: 539880
  training_iteration: 160
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:43 (running for 00:03:43.33)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    160 |          200.761 | 539880 |        0 |                    0 |                    0 |            16.6008 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 551658
  custom_metrics: {}
  date: 2022-04-22_01-32-48
  done: false
  episode_len_mean: 14.95
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 260
  episodes_total: 35246
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 551320
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 698391.5
          max_q: 3783547904.0
          mean_q: 1228855424.0
          min_q: 108447680.0
        mean_td_error: 433500192.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -45046912.0
        - -1780077952.0
        - -135271104.0
        - -1780077952.0
        - -286858112.0
        - -241134848.0
        - -174181792.0
        - -122487680.0
        - -200654336.0
        - 3783547904.0
        - -1780077952.0
        - 684737600.0
        - -229339072.0
        - -145274240.0
        - 2416804608.0
        - -241134848.0
        - -197790592.0
        - 684737600.0
        - -229339072.0
        - 2416804608.0
        - 3783547904.0
        - 3783547904.0
        - -145274240.0
        - -174181792.0
        - -122131968.0
        - 3783547904.0
        - -1780077952.0
        - -1780077952.0
        - 3783547904.0
        - 684737600.0
        - -197790592.0
        - -145274240.0
    num_agent_steps_sampled: 551658
    num_agent_steps_trained: 80128
    num_steps_sampled: 551760
    num_steps_trained: 40064
    num_steps_trained_this_iter: 32
    num_target_updates: 626
  iterations_since_restore: 164
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.149999999999999
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.26153846153846155
    player_1: 0.26153846153846155
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08129556670973898
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.621820431609844
    mean_inference_ms: 1.1533183332174686
    mean_raw_obs_processing_ms: 0.3714771409735937
  time_since_restore: 205.21553945541382
  time_this_iter_s: 1.37148118019104
  time_total_s: 205.21553945541382
  timers:
    learn_throughput: 1548.437
    learn_time_ms: 20.666
    update_time_ms: 20.294
  timestamp: 1650591168
  timesteps_since_restore: 5248
  timesteps_this_iter: 32
  timesteps_total: 551760
  training_iteration: 164
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:49 (running for 00:03:49.37)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    165 |          206.507 | 554400 |        0 |                    0 |                    0 |             15.093 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 563535
  custom_metrics: {}
  date: 2022-04-22_01-32-53
  done: false
  episode_len_mean: 15.422360248447205
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 161
  episodes_total: 35986
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 563640
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1101541.625
          max_q: 3908560384.0
          mean_q: 1611163904.0
          min_q: 116814608.0
        mean_td_error: 923022464.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 813823296.0
        - -180197088.0
        - -1642686976.0
        - -180197088.0
        - 3908560384.0
        - -180197088.0
        - 3908560384.0
        - -233896112.0
        - 2574011392.0
        - -174911360.0
        - 3908560384.0
        - -179088128.0
        - 3908560384.0
        - 813823296.0
        - -176308144.0
        - -268368640.0
        - 2574011392.0
        - 3908560384.0
        - -176308144.0
        - -185207808.0
        - -233896112.0
        - -1642686976.0
        - -176308144.0
        - -197602048.0
        - 3908560384.0
        - 2574011392.0
        - 710337408.0
        - -200495104.0
        - -148605888.0
        - 2574011392.0
        - -191595392.0
        - -180115616.0
    num_agent_steps_sampled: 563535
    num_agent_steps_trained: 81856
    num_steps_sampled: 563640
    num_steps_trained: 40928
    num_steps_trained_this_iter: 32
    num_target_updates: 640
  iterations_since_restore: 168
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.300000000000001
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.18633540372670807
    player_1: 0.18633540372670807
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.0817457351372506
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6261543672096728
    mean_inference_ms: 1.1600042871048444
    mean_raw_obs_processing_ms: 0.37488104021742463
  time_since_restore: 210.1635925769806
  time_this_iter_s: 1.3319790363311768
  time_total_s: 210.1635925769806
  timers:
    learn_throughput: 1536.774
    learn_time_ms: 20.823
    update_time_ms: 19.402
  timestamp: 1650591173
  timesteps_since_restore: 5376
  timesteps_this_iter: 32
  timesteps_total: 563640
  training_iteration: 168
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:32:55 (running for 00:03:55.33)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    169 |          211.534 | 567600 |        0 |                    0 |                    0 |             16.754 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 575416
  custom_metrics: {}
  date: 2022-04-22_01-32-59
  done: false
  episode_len_mean: 15.48502994011976
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 167
  episodes_total: 36729
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 575080
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 12317758.0
          max_q: 4183237632.0
          mean_q: 1813568896.0
          min_q: 127940752.0
        mean_td_error: 824312320.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 4183237632.0
        - 763308992.0
        - 883278464.0
        - -250849520.0
        - 883278464.0
        - 4183237632.0
        - -242801664.0
        - -113850368.0
        - 4183237632.0
        - -182220160.0
        - -144109568.0
        - -181842048.0
        - 4183237632.0
        - 4183237632.0
        - -113850368.0
        - -188330448.0
        - -242801664.0
        - -186113280.0
        - 4183237632.0
        - 4183237632.0
        - -165535872.0
        - -187490432.0
        - -173804736.0
        - -1610655232.0
        - -188330448.0
        - -144109568.0
        - -144109568.0
        - -188054896.0
        - -182264512.0
        - -172329152.0
        - -188278208.0
        - -242801664.0
    num_agent_steps_sampled: 575416
    num_agent_steps_trained: 83584
    num_steps_sampled: 575520
    num_steps_trained: 41792
    num_steps_trained_this_iter: 32
    num_target_updates: 653
  iterations_since_restore: 172
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.75
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.25748502994011974
    player_1: 0.25748502994011974
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08135662931729881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6223023314604407
    mean_inference_ms: 1.1542264410547853
    mean_raw_obs_processing_ms: 0.3717512184609022
  time_since_restore: 214.606379032135
  time_this_iter_s: 1.294459342956543
  time_total_s: 214.606379032135
  timers:
    learn_throughput: 1569.692
    learn_time_ms: 20.386
    update_time_ms: 20.708
  timestamp: 1650591179
  timesteps_since_restore: 5504
  timesteps_this_iter: 32
  timesteps_total: 575520
  training_iteration: 172
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:01 (running for 00:04:01.45)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    174 |          217.369 | 583440 |        0 |                    0 |                    0 |            15.9355 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 589935
  custom_metrics: {}
  date: 2022-04-22_01-33-04
  done: false
  episode_len_mean: 17.02173913043478
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 230
  episodes_total: 37624
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 590040
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 23070928.0
          max_q: 4628279296.0
          mean_q: 1606028416.0
          min_q: 145377792.0
        mean_td_error: 560629952.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -141009408.0
        - -128762624.0
        - -1592296192.0
        - 4628279296.0
        - -185091136.0
        - 844916672.0
        - -217902016.0
        - 4628279296.0
        - 4628279296.0
        - -141009408.0
        - -228915968.0
        - -190098368.0
        - 4628279296.0
        - 575224832.0
        - -223468160.0
        - -165548288.0
        - -223468160.0
        - -295979968.0
        - -273063744.0
        - 844916672.0
        - -1592296192.0
        - 1006082816.0
        - -128762624.0
        - -273063744.0
        - 1198407424.0
        - -220567040.0
        - 844916672.0
        - -185063744.0
        - -295979968.0
        - -204358656.0
        - -179126720.0
        - 1198407424.0
    num_agent_steps_sampled: 589935
    num_agent_steps_trained: 85696
    num_steps_sampled: 590040
    num_steps_trained: 42848
    num_steps_trained_this_iter: 32
    num_target_updates: 670
  iterations_since_restore: 176
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 9.25
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.2391304347826087
    player_1: 0.2391304347826087
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.0810871996057058
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6198552762038549
    mean_inference_ms: 1.151131521317951
    mean_raw_obs_processing_ms: 0.3705138200646818
  time_since_restore: 219.9784185886383
  time_this_iter_s: 1.3109149932861328
  time_total_s: 219.9784185886383
  timers:
    learn_throughput: 1610.501
    learn_time_ms: 19.87
    update_time_ms: 17.94
  timestamp: 1650591184
  timesteps_since_restore: 5632
  timesteps_this_iter: 32
  timesteps_total: 590040
  training_iteration: 176
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:07 (running for 00:04:06.93)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    178 |          222.622 | 596640 |        0 |                    0 |                    0 |            15.3272 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 604455
  custom_metrics: {}
  date: 2022-04-22_01-33-10
  done: false
  episode_len_mean: 15.520912547528518
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 263
  episodes_total: 38576
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 604120
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 585578.875
          max_q: 5033975808.0
          mean_q: 2046578816.0
          min_q: 162555424.0
        mean_td_error: 1018476992.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 643589248.0
        - 5033975808.0
        - -218546432.0
        - -166068992.0
        - 5033975808.0
        - 643589248.0
        - -271877120.0
        - -166068992.0
        - 5033975808.0
        - 643589248.0
        - -140088064.0
        - -1496825472.0
        - 5033975808.0
        - -180431168.0
        - -1496825472.0
        - -287137024.0
        - -404574720.0
        - 1125791104.0
        - 1125791104.0
        - -218333344.0
        - 5033975808.0
        - 5033975808.0
        - -338406656.0
        - -269462720.0
        - -269169664.0
        - 643589248.0
        - -269462720.0
        - -1496825472.0
        - 643589248.0
        - 5033975808.0
        - -285878016.0
        - -140112000.0
    num_agent_steps_sampled: 604455
    num_agent_steps_trained: 87808
    num_steps_sampled: 604560
    num_steps_trained: 43904
    num_steps_trained_this_iter: 32
    num_target_updates: 686
  iterations_since_restore: 180
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.55
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.41825095057034223
    player_1: 0.41825095057034223
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08129598362977314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6216834016744116
    mean_inference_ms: 1.1532970476386966
    mean_raw_obs_processing_ms: 0.3712870342619792
  time_since_restore: 225.43265461921692
  time_this_iter_s: 1.3822593688964844
  time_total_s: 225.43265461921692
  timers:
    learn_throughput: 1560.697
    learn_time_ms: 20.504
    update_time_ms: 20.178
  timestamp: 1650591190
  timesteps_since_restore: 5760
  timesteps_this_iter: 32
  timesteps_total: 604560
  training_iteration: 180
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:13 (running for 00:04:12.83)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    182 |          227.637 | 609840 |        0 |                    0 |                    0 |            16.3556 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 617657
  custom_metrics: {}
  date: 2022-04-22_01-33-16
  done: false
  episode_len_mean: 16.162393162393162
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 234
  episodes_total: 39389
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 617320
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 2543577.5
          max_q: 3557510144.0
          mean_q: 1493749632.0
          min_q: 182672528.0
        mean_td_error: 30073848.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -322726656.0
        - -339153664.0
        - -347722880.0
        - -324016896.0
        - -307945216.0
        - 1285314048.0
        - -339153664.0
        - 1284442624.0
        - 1284442624.0
        - -357580800.0
        - 733313536.0
        - -186078720.0
        - -77776640.0
        - -339153664.0
        - -307945216.0
        - 1284442624.0
        - 1284442624.0
        - -251399280.0
        - -341812736.0
        - -251633712.0
        - -209958912.0
        - -357580800.0
        - -339153664.0
        - 1285314048.0
        - -410234496.0
        - -307945216.0
        - -357580800.0
        - -209958912.0
        - -307945216.0
        - -214441728.0
        - -347722880.0
        - -322726656.0
    num_agent_steps_sampled: 617657
    num_agent_steps_trained: 89728
    num_steps_sampled: 617760
    num_steps_trained: 44864
    num_steps_trained_this_iter: 32
    num_target_updates: 701
  iterations_since_restore: 184
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.2
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3418803418803419
    player_1: 0.3418803418803419
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08111774234210979
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6204113923385348
    mean_inference_ms: 1.1514064632736467
    mean_raw_obs_processing_ms: 0.37113959202844393
  time_since_restore: 230.69553756713867
  time_this_iter_s: 1.7502186298370361
  time_total_s: 230.69553756713867
  timers:
    learn_throughput: 1579.248
    learn_time_ms: 20.263
    update_time_ms: 21.191
  timestamp: 1650591196
  timesteps_since_restore: 5888
  timesteps_this_iter: 32
  timesteps_total: 617760
  training_iteration: 184
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:19 (running for 00:04:18.80)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    186 |          233.373 | 625680 |        0 |                    0 |                    0 |            17.1878 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 632179
  custom_metrics: {}
  date: 2022-04-22_01-33-22
  done: false
  episode_len_mean: 15.834008097165992
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 247
  episodes_total: 40281
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 632280
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 37860780.0
          max_q: 6105817600.0
          mean_q: 2130896512.0
          min_q: 204544864.0
        mean_td_error: 678690112.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -229777664.0
        - -336068608.0
        - -311258112.0
        - -391230880.0
        - 3300274688.0
        - -314600704.0
        - -336068608.0
        - -314972736.0
        - 2129151232.0
        - -314600704.0
        - -224418688.0
        - 1831765504.0
        - -412297920.0
        - 3300274688.0
        - -412297920.0
        - -263795456.0
        - 3300274688.0
        - -263795456.0
        - -224418688.0
        - -336068608.0
        - 3300274688.0
        - -348140800.0
        - 3300274688.0
        - 832142720.0
        - -342702336.0
        - 1831765504.0
        - 1831765504.0
        - 3300274688.0
        - -311258112.0
        - -263795456.0
        - -364169216.0
        - -224418688.0
    num_agent_steps_sampled: 632179
    num_agent_steps_trained: 91840
    num_steps_sampled: 632280
    num_steps_trained: 45920
    num_steps_trained_this_iter: 32
    num_target_updates: 718
  iterations_since_restore: 188
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.65
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3076923076923077
    player_1: 0.3076923076923077
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08142627115323436
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6225990461448534
    mean_inference_ms: 1.1553922550444753
    mean_raw_obs_processing_ms: 0.3720501762923006
  time_since_restore: 236.03423690795898
  time_this_iter_s: 1.35420823097229
  time_total_s: 236.03423690795898
  timers:
    learn_throughput: 1561.087
    learn_time_ms: 20.499
    update_time_ms: 20.75
  timestamp: 1650591202
  timesteps_since_restore: 6016
  timesteps_this_iter: 32
  timesteps_total: 632280
  training_iteration: 188
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:24 (running for 00:04:24.20)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    190 |          237.855 | 637560 |        0 |                    0 |                    0 |               16.4 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 644059
  custom_metrics: {}
  date: 2022-04-22_01-33-27
  done: false
  episode_len_mean: 16.321428571428573
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 252
  episodes_total: 41033
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 643720
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1619691.875
          max_q: 4683920896.0
          mean_q: 1734127232.0
          min_q: 219759008.0
        mean_td_error: 457314496.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -330390368.0
        - -296284928.0
        - -327264512.0
        - 661001856.0
        - -296284928.0
        - 899755392.0
        - -295610624.0
        - -259200512.0
        - -330390368.0
        - 2305162752.0
        - -225332736.0
        - 2305533440.0
        - 899755392.0
        - 661001856.0
        - -318743040.0
        - 899886720.0
        - 2305533440.0
        - -318780160.0
        - -318780160.0
        - 899886720.0
        - -323256832.0
        - -335485056.0
        - -328026368.0
        - 661001856.0
        - 2305533440.0
        - -227349888.0
        - -296165120.0
        - 899886720.0
        - 3628564992.0
        - 899755392.0
        - -440459264.0
        - -330390368.0
    num_agent_steps_sampled: 644059
    num_agent_steps_trained: 93568
    num_steps_sampled: 644160
    num_steps_trained: 46784
    num_steps_trained_this_iter: 32
    num_target_updates: 731
  iterations_since_restore: 192
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.8
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.35714285714285715
    player_1: 0.35714285714285715
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.0811770830259584
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6209891209462699
    mean_inference_ms: 1.1516167875732426
    mean_raw_obs_processing_ms: 0.3708843137604413
  time_since_restore: 240.5611047744751
  time_this_iter_s: 1.3689656257629395
  time_total_s: 240.5611047744751
  timers:
    learn_throughput: 1541.069
    learn_time_ms: 20.765
    update_time_ms: 20.019
  timestamp: 1650591207
  timesteps_since_restore: 6144
  timesteps_this_iter: 32
  timesteps_total: 644160
  training_iteration: 192
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:30 (running for 00:04:29.83)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    194 |           243.25 | 650760 |        0 |                    0 |                    0 |            16.1419 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 658580
  custom_metrics: {}
  date: 2022-04-22_01-33-33
  done: false
  episode_len_mean: 16.43548387096774
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 248
  episodes_total: 41914
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 658680
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 32909714.0
          max_q: 7657628672.0
          mean_q: 2724456448.0
          min_q: 242984784.0
        mean_td_error: 834185920.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 4134897408.0
        - 2592963072.0
        - -273975808.0
        - -317568512.0
        - -229241856.0
        - 1124345600.0
        - 4134897408.0
        - 2592963072.0
        - 2285948928.0
        - 1124345600.0
        - -366051968.0
        - 1124345600.0
        - -376756480.0
        - 4134897408.0
        - 2592963072.0
        - -317568512.0
        - -306723584.0
        - -230083328.0
        - -366509888.0
        - -376756480.0
        - -357796224.0
        - 2285948928.0
        - -377235008.0
        - -289020928.0
        - -366051968.0
        - -351176192.0
        - -332127232.0
        - -332127232.0
        - 2593371648.0
        - 2285948928.0
        - -369881216.0
        - -377235008.0
    num_agent_steps_sampled: 658580
    num_agent_steps_trained: 95680
    num_steps_sampled: 658680
    num_steps_trained: 47840
    num_steps_trained_this_iter: 32
    num_target_updates: 748
  iterations_since_restore: 196
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.5
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3548387096774194
    player_1: 0.3548387096774194
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08112149728011063
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6209011638975284
    mean_inference_ms: 1.1511419564235936
    mean_raw_obs_processing_ms: 0.371107489134037
  time_since_restore: 246.03253293037415
  time_this_iter_s: 1.3892955780029297
  time_total_s: 246.03253293037415
  timers:
    learn_throughput: 1544.474
    learn_time_ms: 20.719
    update_time_ms: 21.709
  timestamp: 1650591213
  timesteps_since_restore: 6272
  timesteps_this_iter: 32
  timesteps_total: 658680
  training_iteration: 196
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:35 (running for 00:04:35.12)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    198 |          248.304 | 663960 |        0 |                    0 |                    0 |            16.8176 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 670455
  custom_metrics: {}
  date: 2022-04-22_01-33-38
  done: false
  episode_len_mean: 15.654545454545454
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 165
  episodes_total: 42660
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 670120
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 14459474.0
          max_q: 6417701888.0
          mean_q: 2722727168.0
          min_q: 269658432.0
        mean_td_error: 582636800.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 2558268416.0
        - -408051584.0
        - -261987840.0
        - 1258807808.0
        - -447478528.0
        - -376025600.0
        - -551366784.0
        - -418617600.0
        - -376806912.0
        - -425514816.0
        - -377221632.0
        - -544551808.0
        - -366613504.0
        - -272479744.0
        - -424986624.0
        - 2558268416.0
        - -419479168.0
        - -418643968.0
        - -327623680.0
        - 3720626944.0
        - -551366784.0
        - 3720626944.0
        - -424986624.0
        - -377221632.0
        - -544551808.0
        - 4635373056.0
        - 1258807808.0
        - 3720626944.0
        - 4635373056.0
        - -397149184.0
        - -354838016.0
        - -354838016.0
    num_agent_steps_sampled: 670455
    num_agent_steps_trained: 97408
    num_steps_sampled: 670560
    num_steps_trained: 48704
    num_steps_trained_this_iter: 32
    num_target_updates: 761
  iterations_since_restore: 200
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.65
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3878787878787879
    player_1: 0.3878787878787879
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08097719880388833
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6192706508032515
    mean_inference_ms: 1.149167112806187
    mean_raw_obs_processing_ms: 0.3702921719035171
  time_since_restore: 250.92114901542664
  time_this_iter_s: 1.3042809963226318
  time_total_s: 250.92114901542664
  timers:
    learn_throughput: 1613.477
    learn_time_ms: 19.833
    update_time_ms: 19.924
  timestamp: 1650591218
  timesteps_since_restore: 6400
  timesteps_this_iter: 32
  timesteps_total: 670560
  training_iteration: 200
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:41 (running for 00:04:40.58)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    202 |          252.708 | 675840 |        0 |                    0 |                    0 |             16.825 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 681015
  custom_metrics: {}
  date: 2022-04-22_01-33-43
  done: false
  episode_len_mean: 15.141242937853107
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 177
  episodes_total: 43319
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 680680
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1704566.625
          max_q: 7918405120.0
          mean_q: 3381633024.0
          min_q: 292553728.0
        mean_td_error: 1264720512.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 3188898816.0
        - -468670208.0
        - 3188413440.0
        - 5094075904.0
        - 3188898816.0
        - -468670208.0
        - -468670208.0
        - 3188898816.0
        - -339552256.0
        - -315670528.0
        - -435317760.0
        - -438990848.0
        - 5094075904.0
        - 1374428544.0
        - 5094075904.0
        - 4075775744.0
        - -465081472.0
        - 3188898816.0
        - -605202624.0
        - -525491712.0
        - -433528832.0
        - -276396288.0
        - -456584320.0
        - 2809052672.0
        - 5094075904.0
        - -456002176.0
        - -468670208.0
        - -365302784.0
        - -494715904.0
        - -276396288.0
        - -425374976.0
        - 4075775744.0
    num_agent_steps_sampled: 681015
    num_agent_steps_trained: 98944
    num_steps_sampled: 681120
    num_steps_trained: 49472
    num_steps_trained_this_iter: 32
    num_target_updates: 773
  iterations_since_restore: 204
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.15
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.2542372881355932
    player_1: 0.2542372881355932
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08062792723542753
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6170327226886085
    mean_inference_ms: 1.145143284256377
    mean_raw_obs_processing_ms: 0.36928201638712677
  time_since_restore: 255.02164101600647
  time_this_iter_s: 1.3302876949310303
  time_total_s: 255.02164101600647
  timers:
    learn_throughput: 1583.501
    learn_time_ms: 20.208
    update_time_ms: 23.654
  timestamp: 1650591223
  timesteps_since_restore: 6528
  timesteps_this_iter: 32
  timesteps_total: 681120
  training_iteration: 204
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:47 (running for 00:04:46.82)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    207 |          258.661 | 690360 |        0 |                    0 |                    0 |            16.4494 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 694219
  custom_metrics: {}
  date: 2022-04-22_01-33-48
  done: false
  episode_len_mean: 15.354961832061068
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 262
  episodes_total: 44141
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 693880
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 66212836.0
          max_q: 8808280064.0
          mean_q: 4293005056.0
          min_q: 323162240.0
        mean_td_error: 1036898432.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -703538176.0
        - -616466176.0
        - -596825600.0
        - -535238656.0
        - -570421248.0
        - -647889920.0
        - 7814103040.0
        - -702142464.0
        - -315828224.0
        - -703538176.0
        - 7814103040.0
        - 3543229184.0
        - 7814103040.0
        - -467654144.0
        - -570421248.0
        - 7814103040.0
        - -562922496.0
        - 3543229184.0
        - -497336704.0
        - -596825600.0
        - -492955520.0
        - 3543229184.0
        - 4535428096.0
        - -597491712.0
        - -532810048.0
        - -497318272.0
        - -467654144.0
        - -703538176.0
        - -345478912.0
        - -596825600.0
        - -377236480.0
        - -542419840.0
    num_agent_steps_sampled: 694219
    num_agent_steps_trained: 100864
    num_steps_sampled: 694320
    num_steps_trained: 50432
    num_steps_trained_this_iter: 32
    num_target_updates: 788
  iterations_since_restore: 208
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.65
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3282442748091603
    player_1: 0.3282442748091603
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08117438201313137
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6210052880425289
    mean_inference_ms: 1.1520606977681933
    mean_raw_obs_processing_ms: 0.37012709029594204
  time_since_restore: 260.02614641189575
  time_this_iter_s: 1.365605115890503
  time_total_s: 260.02614641189575
  timers:
    learn_throughput: 1552.14
    learn_time_ms: 20.617
    update_time_ms: 19.645
  timestamp: 1650591228
  timesteps_since_restore: 6656
  timesteps_this_iter: 32
  timesteps_total: 694320
  training_iteration: 208
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:52 (running for 00:04:52.08)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    211 |          263.683 | 703560 |        0 |                    0 |                    0 |             16.186 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 710058
  custom_metrics: {}
  date: 2022-04-22_01-33-54
  done: false
  episode_len_mean: 17.565573770491802
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 244
  episodes_total: 45111
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 709720
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 45832752.0
          max_q: 8933221376.0
          mean_q: 3861430784.0
          min_q: 366660960.0
        mean_td_error: 1465636352.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 8933221376.0
        - -561490688.0
        - 4048441856.0
        - -681162752.0
        - -516122112.0
        - -618084224.0
        - -618084224.0
        - -516122112.0
        - -516122112.0
        - -681128960.0
        - -516939264.0
        - -516939264.0
        - -618356480.0
        - 8933221376.0
        - 5189935104.0
        - 5189935104.0
        - -293340160.0
        - -639046400.0
        - -641026304.0
        - -701401600.0
        - -517410560.0
        - -618796672.0
        - -618084224.0
        - -679762432.0
        - 8933221376.0
        - -679762432.0
        - -458993152.0
        - 5189935104.0
        - 5189935104.0
        - 8933221376.0
        - -814443520.0
        - -618084224.0
    num_agent_steps_sampled: 710058
    num_agent_steps_trained: 103168
    num_steps_sampled: 710160
    num_steps_trained: 51584
    num_steps_trained_this_iter: 32
    num_target_updates: 806
  iterations_since_restore: 213
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.4
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.35655737704918034
    player_1: 0.35655737704918034
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08102051811535058
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6195085303275929
    mean_inference_ms: 1.149306984585898
    mean_raw_obs_processing_ms: 0.36954532901681386
  time_since_restore: 265.9872863292694
  time_this_iter_s: 1.356093406677246
  time_total_s: 265.9872863292694
  timers:
    learn_throughput: 1609.337
    learn_time_ms: 19.884
    update_time_ms: 19.104
  timestamp: 1650591234
  timesteps_since_restore: 6816
  timesteps_this_iter: 32
  timesteps_total: 710160
  training_iteration: 213
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:33:58 (running for 00:04:57.66)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    215 |           268.28 | 715440 |        0 |                    0 |                    0 |            15.3071 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 721936
  custom_metrics: {}
  date: 2022-04-22_01-34-00
  done: false
  episode_len_mean: 18.597122302158272
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 139
  episodes_total: 45835
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 722040
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1360021.25
          max_q: 11297550336.0
          mean_q: 6096112128.0
          min_q: 406546944.0
        mean_td_error: 3421009408.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -511205888.0
        - -704628096.0
        - -489208832.0
        - -511205888.0
        - 10011410432.0
        - 10011410432.0
        - 5817400320.0
        - 10011410432.0
        - -753650688.0
        - 5817400320.0
        - -489208832.0
        - -945990656.0
        - -515949824.0
        - 10011410432.0
        - -898375040.0
        - -736539136.0
        - 10011410432.0
        - -753650688.0
        - 5817400320.0
        - -688802816.0
        - 5817400320.0
        - -700674304.0
        - 10011410432.0
        - -515949824.0
        - 10011410432.0
        - 5817400320.0
        - 5817400320.0
        - 10011410432.0
        - -800851968.0
        - -700674304.0
        - -624220032.0
        - 5817400320.0
    num_agent_steps_sampled: 721936
    num_agent_steps_trained: 104896
    num_steps_sampled: 722040
    num_steps_trained: 52448
    num_steps_trained_this_iter: 32
    num_target_updates: 820
  iterations_since_restore: 217
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.0
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.23741007194244604
    player_1: 0.23741007194244604
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08066634429749546
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6170056468953569
    mean_inference_ms: 1.1454644974169488
    mean_raw_obs_processing_ms: 0.3679146045268307
  time_since_restore: 270.98901200294495
  time_this_iter_s: 1.3222439289093018
  time_total_s: 270.98901200294495
  timers:
    learn_throughput: 1590.159
    learn_time_ms: 20.124
    update_time_ms: 21.081
  timestamp: 1650591240
  timesteps_since_restore: 6944
  timesteps_this_iter: 32
  timesteps_total: 722040
  training_iteration: 217
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:03 (running for 00:05:03.32)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    219 |          273.704 | 729960 |        0 |                    0 |                    0 |            16.4681 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 736454
  custom_metrics: {}
  date: 2022-04-22_01-34-06
  done: false
  episode_len_mean: 15.88135593220339
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 236
  episodes_total: 46714
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 736120
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4111134.5
          max_q: 14328630272.0
          mean_q: 4217155072.0
          min_q: 452303872.0
        mean_td_error: 58203288.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -576555008.0
        - 6557336576.0
        - -786520704.0
        - -785996416.0
        - -706740480.0
        - -1058258944.0
        - 1494498560.0
        - 2193037056.0
        - -816486272.0
        - -576555008.0
        - -816904960.0
        - -707560320.0
        - -816486272.0
        - -699016064.0
        - 6634130432.0
        - -576555008.0
        - -999491584.0
        - -876586496.0
        - -699016064.0
        - -1005066496.0
        - -785996416.0
        - -816904960.0
        - -858910720.0
        - -635972608.0
        - -1000081408.0
        - -707560320.0
        - -878487040.0
        - -1176192000.0
        - -1005066496.0
        - -878487040.0
        - 6634130432.0
        - -403172352.0
    num_agent_steps_sampled: 736454
    num_agent_steps_trained: 107008
    num_steps_sampled: 736560
    num_steps_trained: 53504
    num_steps_trained_this_iter: 32
    num_target_updates: 836
  iterations_since_restore: 221
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.55
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3389830508474576
    player_1: 0.3389830508474576
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08075101487275847
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.618285289592391
    mean_inference_ms: 1.1465962071743794
    mean_raw_obs_processing_ms: 0.369483456406102
  time_since_restore: 276.38625049591064
  time_this_iter_s: 1.3255863189697266
  time_total_s: 276.38625049591064
  timers:
    learn_throughput: 1613.345
    learn_time_ms: 19.835
    update_time_ms: 20.092
  timestamp: 1650591246
  timesteps_since_restore: 7072
  timesteps_this_iter: 32
  timesteps_total: 736560
  training_iteration: 221
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:09 (running for 00:05:08.99)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    223 |          279.132 | 743160 |        0 |                    0 |                    0 |             14.797 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 748338
  custom_metrics: {}
  date: 2022-04-22_01-34-12
  done: false
  episode_len_mean: 15.22
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 82
  episodes_total: 47488
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 748440
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 2539136.5
          max_q: 15649404928.0
          mean_q: 5444871680.0
          min_q: 1363971968.0
        mean_td_error: 1933408768.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -1123693568.0
        - -866367488.0
        - 5497116672.0
        - -764123648.0
        - -1136933376.0
        - 7158658048.0
        - 5497116672.0
        - -525291392.0
        - -763177088.0
        - -228111360.0
        - -525291392.0
        - -654519040.0
        - 7158658048.0
        - -525955584.0
        - 7158658048.0
        - 7242439680.0
        - -886513920.0
        - -228111360.0
        - -684417792.0
        - 7242439680.0
        - -764047360.0
        - -228111360.0
        - -1123693568.0
        - 5497116672.0
        - 7242439680.0
        - 7242439680.0
        - -886059520.0
        - 7242439680.0
        - 2392972800.0
        - -921911040.0
        - -921911040.0
        - -945166848.0
    num_agent_steps_sampled: 748338
    num_agent_steps_trained: 108736
    num_steps_sampled: 748440
    num_steps_trained: 54368
    num_steps_trained_this_iter: 32
    num_target_updates: 850
  iterations_since_restore: 225
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 3.7
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.35
    player_1: 0.35
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.07993811240283197
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6092502540290194
    mean_inference_ms: 1.1308031939995946
    mean_raw_obs_processing_ms: 0.36022880659967405
  time_since_restore: 280.96790981292725
  time_this_iter_s: 0.47496533393859863
  time_total_s: 280.96790981292725
  timers:
    learn_throughput: 1525.231
    learn_time_ms: 20.98
    update_time_ms: 20.718
  timestamp: 1650591252
  timesteps_since_restore: 7200
  timesteps_this_iter: 32
  timesteps_total: 748440
  training_iteration: 225
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:15 (running for 00:05:14.55)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    227 |          283.644 | 755040 |        0 |                    0 |                    0 |            17.4348 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 762856
  custom_metrics: {}
  date: 2022-04-22_01-34-17
  done: false
  episode_len_mean: 17.232365145228215
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 241
  episodes_total: 48341
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 762520
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 2372169.75
          max_q: 11754562560.0
          mean_q: 3959061760.0
          min_q: 791223424.0
        mean_td_error: 501952032.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -846692224.0
        - 6106810880.0
        - -1287334912.0
        - -1152313344.0
        - -846793472.0
        - -1021110016.0
        - -1002140416.0
        - 2656130304.0
        - -1129985536.0
        - 8046287872.0
        - -762324992.0
        - 2656130304.0
        - -815614976.0
        - -1047536128.0
        - -1002112512.0
        - -846692224.0
        - -1129643008.0
        - 8046287872.0
        - -1002112512.0
        - 8046287872.0
        - -833871360.0
        - -1021110016.0
        - -1021513728.0
        - -756192000.0
        - -1047536128.0
        - -651929088.0
        - -981159168.0
        - -1002112512.0
        - -1021513728.0
        - 833939328.0
        - -756192000.0
        - 2656130304.0
    num_agent_steps_sampled: 762856
    num_agent_steps_trained: 110848
    num_steps_sampled: 762960
    num_steps_trained: 55424
    num_steps_trained_this_iter: 32
    num_target_updates: 866
  iterations_since_restore: 229
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.7
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3112033195020747
    player_1: 0.3112033195020747
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08111339881778334
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6209928172022904
    mean_inference_ms: 1.151672434716537
    mean_raw_obs_processing_ms: 0.36966775668693347
  time_since_restore: 286.4413197040558
  time_this_iter_s: 1.4273598194122314
  time_total_s: 286.4413197040558
  timers:
    learn_throughput: 1550.064
    learn_time_ms: 20.644
    update_time_ms: 23.428
  timestamp: 1650591257
  timesteps_since_restore: 7328
  timesteps_this_iter: 32
  timesteps_total: 762960
  training_iteration: 229
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:20 (running for 00:05:19.84)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    231 |          288.691 | 768240 |        0 |                    0 |                    0 |            14.9887 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 774734
  custom_metrics: {}
  date: 2022-04-22_01-34-23
  done: false
  episode_len_mean: 15.762195121951219
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 164
  episodes_total: 49083
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 774840
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 1826727.5
          max_q: 14595648512.0
          mean_q: 4882967552.0
          min_q: 751543040.0
        mean_td_error: 1425386624.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 2862061824.0
        - -807243776.0
        - -1067696128.0
        - -1109898752.0
        - -809575168.0
        - 2862061824.0
        - -1207498240.0
        - -1383008256.0
        - 2862061824.0
        - 792219776.0
        - 6679105536.0
        - 2862061824.0
        - -1336574976.0
        - 6679105536.0
        - 6679105536.0
        - -1207498240.0
        - -1127895168.0
        - 6587957760.0
        - -1088585728.0
        - 6679105536.0
        - 2862061824.0
        - -809575168.0
        - -807243776.0
        - -1088585728.0
        - -1067722240.0
        - -619966464.0
        - 6587957760.0
        - -1067696128.0
        - -1207498240.0
        - 2862061824.0
        - 6679105536.0
        - -1109898752.0
    num_agent_steps_sampled: 774734
    num_agent_steps_trained: 112576
    num_steps_sampled: 774840
    num_steps_trained: 56288
    num_steps_trained_this_iter: 32
    num_target_updates: 880
  iterations_since_restore: 233
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.1
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.21341463414634146
    player_1: 0.21341463414634146
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08097672574307856
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6186044947272198
    mean_inference_ms: 1.1484870092405208
    mean_raw_obs_processing_ms: 0.3683645332061198
  time_since_restore: 291.39060497283936
  time_this_iter_s: 1.3317546844482422
  time_total_s: 291.39060497283936
  timers:
    learn_throughput: 1591.398
    learn_time_ms: 20.108
    update_time_ms: 21.486
  timestamp: 1650591263
  timesteps_since_restore: 7456
  timesteps_this_iter: 32
  timesteps_total: 774840
  training_iteration: 233
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:25 (running for 00:05:25.08)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    235 |          293.706 | 781440 |        0 |                    0 |                    0 |            17.4059 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 786618
  custom_metrics: {}
  date: 2022-04-22_01-34-28
  done: false
  episode_len_mean: 15.79
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 87
  episodes_total: 49819
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 786280
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 98358040.0
          max_q: 14090346496.0
          mean_q: 7347630080.0
          min_q: 2817299456.0
        mean_td_error: 1681641728.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -1297952768.0
        - -944638976.0
        - 3124419840.0
        - 3124419840.0
        - 7313533440.0
        - -1477108736.0
        - -1159300352.0
        - -1477108736.0
        - -1477108736.0
        - 3124419840.0
        - -1297952768.0
        - 7211621376.0
        - -1300000768.0
        - -1164201984.0
        - 7313533440.0
        - -1164201984.0
        - -1246573568.0
        - 7211621376.0
        - 3124419840.0
        - 7211621376.0
        - 3124419840.0
        - -1335748608.0
        - -1300000768.0
        - 7211621376.0
        - -1477108736.0
        - -1133954304.0
        - -1297952768.0
        - 7211621376.0
        - 7211621376.0
        - -979860224.0
        - 3124419840.0
        - -1300000768.0
    num_agent_steps_sampled: 786618
    num_agent_steps_trained: 114304
    num_steps_sampled: 786720
    num_steps_trained: 57152
    num_steps_trained_this_iter: 32
    num_target_updates: 893
  iterations_since_restore: 237
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 3.55
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.31
    player_1: 0.31
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08045140732095786
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.614036828516013
    mean_inference_ms: 1.1385920129111786
    mean_raw_obs_processing_ms: 0.3631732722596878
  time_since_restore: 295.94219183921814
  time_this_iter_s: 0.4694337844848633
  time_total_s: 295.94219183921814
  timers:
    learn_throughput: 1597.161
    learn_time_ms: 20.036
    update_time_ms: 20.515
  timestamp: 1650591268
  timesteps_since_restore: 7584
  timesteps_this_iter: 32
  timesteps_total: 786720
  training_iteration: 237
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:31 (running for 00:05:31.20)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    239 |           298.68 | 794640 |        0 |                    0 |                    0 |            15.4016 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 801136
  custom_metrics: {}
  date: 2022-04-22_01-34-34
  done: false
  episode_len_mean: 15.902654867256636
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 226
  episodes_total: 50740
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 801240
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6521862.5
          max_q: 15854403584.0
          mean_q: 7728876032.0
          min_q: 3161779968.0
        mean_td_error: 464049472.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 8111549440.0
        - -1133588480.0
        - -1214343168.0
        - 3500553216.0
        - -1196051456.0
        - -578034688.0
        - 3500553216.0
        - -1104992256.0
        - -1104992256.0
        - -1111651328.0
        - -1212889088.0
        - -1111651328.0
        - 8111549440.0
        - -1104437248.0
        - -1209965568.0
        - -1192716800.0
        - -1111651328.0
        - -1212840960.0
        - -578034688.0
        - -1192716800.0
        - -1192127488.0
        - -1567073536.0
        - 3500553216.0
        - -1196051456.0
        - -578034688.0
        - -1214343168.0
        - -1567073536.0
        - 3500553216.0
        - 3500553216.0
        - 3500553216.0
        - -1192127488.0
        - 3500553216.0
    num_agent_steps_sampled: 801136
    num_agent_steps_trained: 116416
    num_steps_sampled: 801240
    num_steps_trained: 58208
    num_steps_trained_this_iter: 32
    num_target_updates: 910
  iterations_since_restore: 241
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.3
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.29646017699115046
    player_1: 0.29646017699115046
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08109577884892216
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6209621791992637
    mean_inference_ms: 1.1512555859470202
    mean_raw_obs_processing_ms: 0.3700006761238749
  time_since_restore: 301.33998131752014
  time_this_iter_s: 1.3500945568084717
  time_total_s: 301.33998131752014
  timers:
    learn_throughput: 1557.061
    learn_time_ms: 20.552
    update_time_ms: 19.946
  timestamp: 1650591274
  timesteps_since_restore: 7712
  timesteps_this_iter: 32
  timesteps_total: 801240
  training_iteration: 241
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:37 (running for 00:05:36.79)
Memory usage on this node: 25.9/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    243 |          304.011 | 807840 |        0 |                    0 |                    0 |            15.4808 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 815654
  custom_metrics: {}
  date: 2022-04-22_01-34-40
  done: false
  episode_len_mean: 15.57258064516129
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 248
  episodes_total: 51643
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 815320
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5416991.5
          max_q: 17877393408.0
          mean_q: 8394258432.0
          min_q: 388791584.0
        mean_td_error: 1409532672.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -1318580736.0
        - 6602249216.0
        - -1310338048.0
        - 3933125888.0
        - -100962880.0
        - -1330908160.0
        - -934791680.0
        - 3933125888.0
        - 9142599680.0
        - -810842112.0
        - 6602249216.0
        - 3933125888.0
        - 6602249216.0
        - -1185220608.0
        - -1330908160.0
        - 3933125888.0
        - -1310550016.0
        - 3933125888.0
        - -1202778112.0
        - -1296955392.0
        - -1310338048.0
        - -934791680.0
        - -1368483328.0
        - -1368483328.0
        - -1330908160.0
        - -1310338048.0
        - 9142599680.0
        - -1310338048.0
        - 3933125888.0
        - 6602249216.0
        - -810842112.0
        - -1310550016.0
    num_agent_steps_sampled: 815654
    num_agent_steps_trained: 118528
    num_steps_sampled: 815760
    num_steps_trained: 59264
    num_steps_trained_this_iter: 32
    num_target_updates: 926
  iterations_since_restore: 245
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.5
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.33064516129032256
    player_1: 0.33064516129032256
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08068002016314652
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6175493906230388
    mean_inference_ms: 1.1449898888795011
    mean_raw_obs_processing_ms: 0.36906990239916426
  time_since_restore: 306.76330757141113
  time_this_iter_s: 1.3280181884765625
  time_total_s: 306.76330757141113
  timers:
    learn_throughput: 1612.2
    learn_time_ms: 19.849
    update_time_ms: 20.55
  timestamp: 1650591280
  timesteps_since_restore: 7840
  timesteps_this_iter: 32
  timesteps_total: 815760
  training_iteration: 245
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:43 (running for 00:05:42.53)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    247 |          309.515 | 822360 |        0 |                    0 |                    0 |            16.0295 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 828856
  custom_metrics: {}
  date: 2022-04-22_01-34-45
  done: false
  episode_len_mean: 15.25
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 176
  episodes_total: 52510
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 828520
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 10876527.0
          max_q: 30556659712.0
          mean_q: 13449443328.0
          min_q: 3892111872.0
        mean_td_error: 1803027328.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 22545954816.0
        - 22545954816.0
        - -1556300800.0
        - 4303015936.0
        - 4303015936.0
        - -765413376.0
        - -1519128064.0
        - -765413376.0
        - -1414794752.0
        - -765413376.0
        - -1380256256.0
        - -1190319104.0
        - -1146944512.0
        - -1299898368.0
        - 4303015936.0
        - -1414794752.0
        - 4303015936.0
        - -1146944512.0
        - -765413376.0
        - -1499527168.0
        - -1190319104.0
        - -1630363648.0
        - -1499527168.0
        - -1414794752.0
        - -1614901248.0
        - -1380944896.0
        - -1556300800.0
        - -1614901248.0
        - 22545954816.0
        - -1299898368.0
        - 4303015936.0
        - -1623552000.0
    num_agent_steps_sampled: 828856
    num_agent_steps_trained: 120448
    num_steps_sampled: 828960
    num_steps_trained: 60224
    num_steps_trained_this_iter: 32
    num_target_updates: 941
  iterations_since_restore: 249
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.0
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3522727272727273
    player_1: 0.3522727272727273
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08118538667886875
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6204814095157622
    mean_inference_ms: 1.151558288155362
    mean_raw_obs_processing_ms: 0.3683483604067337
  time_since_restore: 312.21366333961487
  time_this_iter_s: 1.3252391815185547
  time_total_s: 312.21366333961487
  timers:
    learn_throughput: 1557.657
    learn_time_ms: 20.544
    update_time_ms: 18.97
  timestamp: 1650591285
  timesteps_since_restore: 7968
  timesteps_this_iter: 32
  timesteps_total: 828960
  training_iteration: 249
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:48 (running for 00:05:47.75)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    250 |          313.558 | 832920 |        0 |                    0 |                    0 |            15.3667 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 842051
  custom_metrics: {}
  date: 2022-04-22_01-34-52
  done: false
  episode_len_mean: 15.885245901639344
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 244
  episodes_total: 53337
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 841720
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 49362448.0
          max_q: 39925272576.0
          mean_q: 17656457216.0
          min_q: 4208498176.0
        mean_td_error: 7707138048.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -1438700544.0
        - -1334950912.0
        - -1339607040.0
        - -1685059584.0
        - -1495363584.0
        - -1665986560.0
        - -1628243968.0
        - 39925272576.0
        - -1295216640.0
        - 24388378624.0
        - -1664727552.0
        - -1514696704.0
        - -1692026880.0
        - -1685059584.0
        - -1334950912.0
        - 39925272576.0
        - -1690085376.0
        - -1669949952.0
        - 24388378624.0
        - -1438700544.0
        - 39925272576.0
        - 24388378624.0
        - 24388378624.0
        - 24388378624.0
        - -1438700544.0
        - -1293850624.0
        - -1514348032.0
        - -1514696704.0
        - 39925272576.0
        - -1514348032.0
        - -1495363584.0
        - -1669949952.0
    num_agent_steps_sampled: 842051
    num_agent_steps_trained: 122368
    num_steps_sampled: 842160
    num_steps_trained: 61184
    num_steps_trained_this_iter: 32
    num_target_updates: 956
  iterations_since_restore: 253
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.45
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.1557377049180328
    player_1: 0.1557377049180328
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08090365634548298
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6194129771352943
    mean_inference_ms: 1.1498978064633891
    mean_raw_obs_processing_ms: 0.3701538523160821
  time_since_restore: 317.2049341201782
  time_this_iter_s: 1.3735146522521973
  time_total_s: 317.2049341201782
  timers:
    learn_throughput: 1562.608
    learn_time_ms: 20.479
    update_time_ms: 20.223
  timestamp: 1650591292
  timesteps_since_restore: 8096
  timesteps_this_iter: 32
  timesteps_total: 842160
  training_iteration: 253
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:54 (running for 00:05:53.59)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    255 |          319.107 | 847440 |        0 |                    0 |                    0 |            15.2811 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 857900
  custom_metrics: {}
  date: 2022-04-22_01-34-58
  done: false
  episode_len_mean: 17.748917748917748
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 231
  episodes_total: 54321
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 857560
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 2807326.5
          max_q: 41600233472.0
          mean_q: 17540825088.0
          min_q: 2674478336.0
        mean_td_error: 9432782848.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 41600233472.0
        - 5041443840.0
        - -1894892544.0
        - -2365073408.0
        - -1149795328.0
        - 41600233472.0
        - -1555716608.0
        - 41600233472.0
        - -4903659520.0
        - 41600233472.0
        - 41600233472.0
        - 41600233472.0
        - -2094303232.0
        - -2060236800.0
        - 41600233472.0
        - -1904864768.0
        - -2365073408.0
        - 41600233472.0
        - -1403624448.0
        - -1373943808.0
        - -1403624448.0
        - -1968447488.0
        - 5041443840.0
        - -4903659520.0
        - -1894892544.0
        - 5041443840.0
        - -4903659520.0
        - -1894892544.0
        - -1555716608.0
        - -1011421184.0
        - -1373943808.0
        - -2095704064.0
    num_agent_steps_sampled: 857900
    num_agent_steps_trained: 124672
    num_steps_sampled: 858000
    num_steps_trained: 62336
    num_steps_trained_this_iter: 32
    num_target_updates: 974
  iterations_since_restore: 258
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.6
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3722943722943723
    player_1: 0.3722943722943723
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08070119887343012
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6179116697090414
    mean_inference_ms: 1.14701597910941
    mean_raw_obs_processing_ms: 0.3682840658272485
  time_since_restore: 323.13502526283264
  time_this_iter_s: 1.3433640003204346
  time_total_s: 323.13502526283264
  timers:
    learn_throughput: 1578.356
    learn_time_ms: 20.274
    update_time_ms: 19.115
  timestamp: 1650591298
  timesteps_since_restore: 8256
  timesteps_this_iter: 32
  timesteps_total: 858000
  training_iteration: 258
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:34:59 (running for 00:05:59.21)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    259 |          324.476 | 860640 |        0 |                    0 |                    0 |            16.0355 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 871097
  custom_metrics: {}
  date: 2022-04-22_01-35-03
  done: false
  episode_len_mean: 16.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 173
  episodes_total: 55147
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 870760
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 62419396.0
          max_q: 42446290944.0
          mean_q: 15948827648.0
          min_q: 735042944.0
        mean_td_error: 8062601216.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -3430307840.0
        - -2298748928.0
        - 42446290944.0
        - -1074044928.0
        - -2925080576.0
        - -1397974528.0
        - -2502640640.0
        - 42446290944.0
        - -1109328896.0
        - -1399443456.0
        - -1399443456.0
        - -2269051904.0
        - -1397974528.0
        - 42446290944.0
        - -3927105024.0
        - 42446290944.0
        - 4856645632.0
        - -2926493696.0
        - -3927105024.0
        - 42446290944.0
        - -667203840.0
        - -2269051904.0
        - -2926493696.0
        - 42446290944.0
        - -2514610176.0
        - -1074044928.0
        - -2298748928.0
        - -1098644864.0
        - -2926493696.0
        - 42446290944.0
        - -1074044928.0
        - 4856645632.0
    num_agent_steps_sampled: 871097
    num_agent_steps_trained: 126592
    num_steps_sampled: 871200
    num_steps_trained: 63296
    num_steps_trained_this_iter: 32
    num_target_updates: 989
  iterations_since_restore: 262
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.0
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3063583815028902
    player_1: 0.3063583815028902
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.080676433633609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6170687719073453
    mean_inference_ms: 1.144629868410512
    mean_raw_obs_processing_ms: 0.36665044181414835
  time_since_restore: 328.52050590515137
  time_this_iter_s: 1.326657772064209
  time_total_s: 328.52050590515137
  timers:
    learn_throughput: 1598.14
    learn_time_ms: 20.023
    update_time_ms: 20.913
  timestamp: 1650591303
  timesteps_since_restore: 8384
  timesteps_this_iter: 32
  timesteps_total: 871200
  training_iteration: 262
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:04 (running for 00:06:04.43)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    263 |          329.462 | 873840 |        0 |                    0 |                    0 |            15.2982 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 881660
  custom_metrics: {}
  date: 2022-04-22_01-35-09
  done: false
  episode_len_mean: 16.6
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 77
  episodes_total: 55798
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 881320
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 3196286.75
          max_q: 43389767680.0
          mean_q: 16474306560.0
          min_q: 1154824064.0
        mean_td_error: 6454637568.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 43389767680.0
        - 43389767680.0
        - -2843294720.0
        - -1202688384.0
        - -2556272640.0
        - -1202688384.0
        - 43389767680.0
        - -939366400.0
        - -1318919168.0
        - -3448070144.0
        - -2862638080.0
        - -4089657344.0
        - -4076908544.0
        - 43389767680.0
        - 43389767680.0
        - -2843294720.0
        - -4089657344.0
        - 5084251648.0
        - -2843294720.0
        - -2556678656.0
        - -2213438464.0
        - -2862638080.0
        - -939366400.0
        - -2213438464.0
        - -2514111488.0
        - -939366400.0
        - -889141248.0
        - -1318919168.0
        - -4076908544.0
        - 43389767680.0
        - -2862638080.0
        - -1171046400.0
    num_agent_steps_sampled: 881660
    num_agent_steps_trained: 128128
    num_steps_sampled: 881760
    num_steps_trained: 64064
    num_steps_trained_this_iter: 32
    num_target_updates: 1001
  iterations_since_restore: 266
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 3.55
    ram_util_percent: 20.75
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.32
    player_1: 0.32
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.0795890475610961
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6079410594516108
    mean_inference_ms: 1.1276240701942506
    mean_raw_obs_processing_ms: 0.3589510740020494
  time_since_restore: 332.6336476802826
  time_this_iter_s: 0.4556434154510498
  time_total_s: 332.6336476802826
  timers:
    learn_throughput: 1581.192
    learn_time_ms: 20.238
    update_time_ms: 20.54
  timestamp: 1650591309
  timesteps_since_restore: 8512
  timesteps_this_iter: 32
  timesteps_total: 881760
  training_iteration: 266
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:10 (running for 00:06:10.12)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    267 |          333.972 | 885720 |        0 |                    0 |                    0 |            17.1646 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 894857
  custom_metrics: {}
  date: 2022-04-22_01-35-14
  done: false
  episode_len_mean: 16.613445378151262
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 238
  episodes_total: 56590
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 894520
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 3068985.0
          max_q: 44234993664.0
          mean_q: 24977408000.0
          min_q: 5332793856.0
        mean_td_error: 15227071488.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -4949803008.0
        - -4899985408.0
        - -2866757120.0
        - 5332793856.0
        - -1206960128.0
        - -708973568.0
        - -2866757120.0
        - -4899985408.0
        - 44234993664.0
        - 44234993664.0
        - 44234993664.0
        - 44234993664.0
        - 44234993664.0
        - -4949803008.0
        - -4899985408.0
        - 44234993664.0
        - -3285841920.0
        - -2866757120.0
        - 44234993664.0
        - -3285841920.0
        - 594737152.0
        - 44234993664.0
        - 44234993664.0
        - -3285841920.0
        - -4899985408.0
        - 44234993664.0
        - 5332793856.0
        - 44234993664.0
        - -1206960128.0
        - -866963456.0
        - -2866757120.0
        - 44234993664.0
    num_agent_steps_sampled: 894857
    num_agent_steps_trained: 130048
    num_steps_sampled: 894960
    num_steps_trained: 65024
    num_steps_trained_this_iter: 32
    num_target_updates: 1016
  iterations_since_restore: 270
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.65
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.36134453781512604
    player_1: 0.36134453781512604
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08080959004410329
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6191657448563261
    mean_inference_ms: 1.148203588784162
    mean_raw_obs_processing_ms: 0.3694274732613294
  time_since_restore: 337.6548750400543
  time_this_iter_s: 1.395249605178833
  time_total_s: 337.6548750400543
  timers:
    learn_throughput: 1540.668
    learn_time_ms: 20.77
    update_time_ms: 22.321
  timestamp: 1650591314
  timesteps_since_restore: 8640
  timesteps_this_iter: 32
  timesteps_total: 894960
  training_iteration: 270
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:15 (running for 00:06:15.38)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    271 |          338.996 | 898920 |        0 |                    0 |                    0 |            16.0517 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 909378
  custom_metrics: {}
  date: 2022-04-22_01-35-20
  done: false
  episode_len_mean: 16.359683794466402
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 253
  episodes_total: 57530
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 909480
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 176566848.0
          max_q: 47923044352.0
          mean_q: 11958647808.0
          min_q: 2880859136.0
        mean_td_error: -429946720.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -1107613184.0
        - -551004160.0
        - 2253273088.0
        - -551004160.0
        - 4505894912.0
        - 4505894912.0
        - -552437760.0
        - -3059132416.0
        - -790258688.0
        - -2987996160.0
        - -488926208.0
        - -3059132416.0
        - -1305176064.0
        - -668616704.0
        - -551004160.0
        - -3059132416.0
        - -3059132416.0
        - -2987996160.0
        - -3462970368.0
        - -668616704.0
        - 5382815744.0
        - -1305176064.0
        - 5382815744.0
        - 905609216.0
        - 4505894912.0
        - -668616704.0
        - -1305176064.0
        - -551004160.0
        - -1305176064.0
        - -2988357120.0
        - -3059132416.0
        - -1107704832.0
    num_agent_steps_sampled: 909378
    num_agent_steps_trained: 132160
    num_steps_sampled: 909480
    num_steps_trained: 66080
    num_steps_trained_this_iter: 32
    num_target_updates: 1033
  iterations_since_restore: 274
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.95
    ram_util_percent: 20.7
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.33992094861660077
    player_1: 0.33992094861660077
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08063735305446618
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6174158136101399
    mean_inference_ms: 1.145185065942414
    mean_raw_obs_processing_ms: 0.36733581687810246
  time_since_restore: 343.1024262905121
  time_this_iter_s: 1.4049596786499023
  time_total_s: 343.1024262905121
  timers:
    learn_throughput: 1522.63
    learn_time_ms: 21.016
    update_time_ms: 21.939
  timestamp: 1650591320
  timesteps_since_restore: 8768
  timesteps_this_iter: 32
  timesteps_total: 909480
  training_iteration: 274
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:21 (running for 00:06:21.06)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    275 |          344.441 | 912120 |        0 |                    0 |                    0 |            15.5924 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 921255
  custom_metrics: {}
  date: 2022-04-22_01-35-25
  done: false
  episode_len_mean: 15.425149700598803
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 167
  episodes_total: 58255
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 920920
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 2604280.75
          max_q: 46638411776.0
          mean_q: 14181494784.0
          min_q: 1174058368.0
        mean_td_error: 4417627136.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 17866043392.0
        - -4747974656.0
        - 26132025344.0
        - -4747974656.0
        - -647522816.0
        - -4135710720.0
        - 5259021312.0
        - -4135710720.0
        - 17866043392.0
        - -1441161216.0
        - -1251886592.0
        - 5259021312.0
        - 26132025344.0
        - 17866043392.0
        - -806152192.0
        - -1071366144.0
        - 5259021312.0
        - -1033604096.0
        - -647522816.0
        - 5259021312.0
        - 353572864.0
        - -1033604096.0
        - -1441161216.0
        - 17866043392.0
        - -1250785792.0
        - 3225853952.0
        - -806152192.0
        - -4747974656.0
        - -2730107904.0
        - 5259021312.0
        - 26132025344.0
        - -1694326400.0
    num_agent_steps_sampled: 921255
    num_agent_steps_trained: 133888
    num_steps_sampled: 921360
    num_steps_trained: 66944
    num_steps_trained_this_iter: 32
    num_target_updates: 1046
  iterations_since_restore: 278
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 6.25
    ram_util_percent: 20.75
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.49101796407185627
    player_1: 0.49101796407185627
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08079628202230506
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.618784575430884
    mean_inference_ms: 1.1476326382998283
    mean_raw_obs_processing_ms: 0.3693590998186636
  time_since_restore: 348.1501636505127
  time_this_iter_s: 1.3929147720336914
  time_total_s: 348.1501636505127
  timers:
    learn_throughput: 1522.653
    learn_time_ms: 21.016
    update_time_ms: 22.111
  timestamp: 1650591325
  timesteps_since_restore: 8896
  timesteps_this_iter: 32
  timesteps_total: 921360
  training_iteration: 278
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:26 (running for 00:06:26.36)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    279 |          349.513 | 925320 |        0 |                    0 |                    0 |            16.5752 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 933138
  custom_metrics: {}
  date: 2022-04-22_01-35-31
  done: false
  episode_len_mean: 17.0125786163522
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 159
  episodes_total: 58951
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 933240
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5954832.5
          max_q: 45237297152.0
          mean_q: 17686067200.0
          min_q: 5118676480.0
        mean_td_error: 5678441984.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -1285170176.0
        - -3222435840.0
        - 25313998848.0
        - 17857177600.0
        - 17857177600.0
        - 1886081024.0
        - 5118987264.0
        - 5118987264.0
        - 5118676480.0
        - -3391297536.0
        - 25313998848.0
        - -1398579200.0
        - 25313998848.0
        - 5118987264.0
        - -1589387776.0
        - -3804651520.0
        - 1886081024.0
        - -3457060864.0
        - -1214291968.0
        - -3804651520.0
        - -2650322944.0
        - -2441726464.0
        - 17857177600.0
        - -2650322944.0
        - -3391297536.0
        - 25313998848.0
        - 5118987264.0
        - 17857177600.0
        - 17857177600.0
        - 567162880.0
        - -1073191936.0
        - -3391297536.0
    num_agent_steps_sampled: 933138
    num_agent_steps_trained: 135616
    num_steps_sampled: 933240
    num_steps_trained: 67808
    num_steps_trained_this_iter: 32
    num_target_updates: 1060
  iterations_since_restore: 282
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 5.5
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3522012578616352
    player_1: 0.3522012578616352
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08033053391978857
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6143128112498225
    mean_inference_ms: 1.140896967218748
    mean_raw_obs_processing_ms: 0.3666504283078295
  time_since_restore: 352.65923523902893
  time_this_iter_s: 1.3583130836486816
  time_total_s: 352.65923523902893
  timers:
    learn_throughput: 1573.226
    learn_time_ms: 20.34
    update_time_ms: 21.396
  timestamp: 1650591331
  timesteps_since_restore: 9024
  timesteps_this_iter: 32
  timesteps_total: 933240
  training_iteration: 282
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:32 (running for 00:06:31.77)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    283 |          353.602 | 935880 |        0 |                    0 |                    0 |            15.9821 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 946338
  custom_metrics: {}
  date: 2022-04-22_01-35-36
  done: false
  episode_len_mean: 14.867469879518072
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 249
  episodes_total: 59782
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 946440
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4555082.0
          max_q: 28944572416.0
          mean_q: 14538177536.0
          min_q: 1168826112.0
        mean_td_error: 7202242560.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -2664752384.0
        - 18681937920.0
        - 5150796800.0
        - -2650296320.0
        - -1847935488.0
        - -1879956992.0
        - -2043360768.0
        - -2053236736.0
        - -1847935488.0
        - -2650296320.0
        - 25404715008.0
        - -2043360768.0
        - 18681937920.0
        - 5150796800.0
        - -2228189184.0
        - 25404715008.0
        - -2053236736.0
        - 25404715008.0
        - 25404715008.0
        - 25404715008.0
        - 25404715008.0
        - -1847935488.0
        - 18681937920.0
        - 25404715008.0
        - -2228189184.0
        - 25404715008.0
        - -1413699584.0
        - -1847935488.0
        - -1413699584.0
        - -1847935488.0
        - -1847935488.0
        - -2703466496.0
    num_agent_steps_sampled: 946338
    num_agent_steps_trained: 137536
    num_steps_sampled: 946440
    num_steps_trained: 68768
    num_steps_trained_this_iter: 32
    num_target_updates: 1075
  iterations_since_restore: 286
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.75
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3172690763052209
    player_1: 0.3172690763052209
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08110599433655352
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6207871535382468
    mean_inference_ms: 1.1506974602670061
    mean_raw_obs_processing_ms: 0.3697668841578343
  time_since_restore: 357.6727600097656
  time_this_iter_s: 1.3778374195098877
  time_total_s: 357.6727600097656
  timers:
    learn_throughput: 1548.464
    learn_time_ms: 20.666
    update_time_ms: 19.023
  timestamp: 1650591336
  timesteps_since_restore: 9152
  timesteps_this_iter: 32
  timesteps_total: 946440
  training_iteration: 286
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:37 (running for 00:06:37.04)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    287 |           358.63 | 949080 |        0 |                    0 |                    0 |            17.1883 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 960855
  custom_metrics: {}
  date: 2022-04-22_01-35-42
  done: false
  episode_len_mean: 16.47107438016529
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 242
  episodes_total: 60656
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 960520
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 4250047.5
          max_q: 49159856128.0
          mean_q: 17873778688.0
          min_q: 1251341952.0
        mean_td_error: 7490954240.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -1991444992.0
        - 20637485056.0
        - -2147852288.0
        - -1092673536.0
        - -1990864896.0
        - -1901858816.0
        - -2079836544.0
        - -2132717056.0
        - -2137024512.0
        - 20637485056.0
        - 27378886656.0
        - -1821190144.0
        - -2147852288.0
        - -1901858816.0
        - -2147852288.0
        - -2244596736.0
        - 5551039488.0
        - -2148564992.0
        - 27378886656.0
        - 27378886656.0
        - -2244596736.0
        - -2135740416.0
        - 20637485056.0
        - -1092673536.0
        - -2796778496.0
        - -1806839808.0
        - 20637485056.0
        - -2079836544.0
        - 27378886656.0
        - 27378886656.0
        - 27378886656.0
        - 27378886656.0
    num_agent_steps_sampled: 960855
    num_agent_steps_trained: 139648
    num_steps_sampled: 960960
    num_steps_trained: 69824
    num_steps_trained_this_iter: 32
    num_target_updates: 1091
  iterations_since_restore: 291
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.45
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.371900826446281
    player_1: 0.371900826446281
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08061351155589788
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6173797876975142
    mean_inference_ms: 1.1446526456021089
    mean_raw_obs_processing_ms: 0.3677795461083133
  time_since_restore: 363.2546474933624
  time_this_iter_s: 1.367584228515625
  time_total_s: 363.2546474933624
  timers:
    learn_throughput: 1559.984
    learn_time_ms: 20.513
    update_time_ms: 20.276
  timestamp: 1650591342
  timesteps_since_restore: 9312
  timesteps_this_iter: 32
  timesteps_total: 960960
  training_iteration: 291
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:43 (running for 00:06:43.31)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    292 |          364.602 | 963600 |        0 |                    0 |                    0 |            16.2866 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 974058
  custom_metrics: {}
  date: 2022-04-22_01-35-48
  done: false
  episode_len_mean: 16.790513833992094
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 253
  episodes_total: 61464
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 973720
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 247680720.0
          max_q: 52873592832.0
          mean_q: 19887165440.0
          min_q: 3624913408.0
        mean_td_error: 13111452672.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -2093286400.0
        - 22244548608.0
        - -2171160576.0
        - 29349220352.0
        - 22244548608.0
        - -2173792256.0
        - 22244548608.0
        - -2470299648.0
        - 29349220352.0
        - 29349220352.0
        - 22244548608.0
        - 29349220352.0
        - 29349220352.0
        - -2981911552.0
        - 22245076992.0
        - 5962251264.0
        - 29349220352.0
        - -2246430720.0
        - 5962251264.0
        - -2171185664.0
        - -2245455872.0
        - -2016792576.0
        - -2010118144.0
        - 5962251264.0
        - -2246430720.0
        - -1384525824.0
        - 22244548608.0
        - 29349220352.0
        - 22244548608.0
        - 22244548608.0
        - 22244548608.0
        - 22245076992.0
    num_agent_steps_sampled: 974058
    num_agent_steps_trained: 141568
    num_steps_sampled: 974160
    num_steps_trained: 70784
    num_steps_trained_this_iter: 32
    num_target_updates: 1106
  iterations_since_restore: 295
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.033333333333332
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3675889328063241
    player_1: 0.3675889328063241
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08057964785633515
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6165498585595978
    mean_inference_ms: 1.1435113852126735
    mean_raw_obs_processing_ms: 0.3671765713624679
  time_since_restore: 368.72326612472534
  time_this_iter_s: 1.7935597896575928
  time_total_s: 368.72326612472534
  timers:
    learn_throughput: 1598.961
    learn_time_ms: 20.013
    update_time_ms: 21.503
  timestamp: 1650591348
  timesteps_since_restore: 9440
  timesteps_this_iter: 32
  timesteps_total: 974160
  training_iteration: 295
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:49 (running for 00:06:49.06)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    296 |          370.113 | 978120 |        0 |                    0 |                    0 |            16.2426 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 984623
  custom_metrics: {}
  date: 2022-04-22_01-35-53
  done: false
  episode_len_mean: 16.838509316770185
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 161
  episodes_total: 62091
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 984280
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7618798.0
          max_q: 38216638464.0
          mean_q: 16883084288.0
          min_q: 1394148608.0
        mean_td_error: 4356865024.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 23502266368.0
        - -1751293952.0
        - -1889542144.0
        - -2385389568.0
        - 25823911936.0
        - 6209150976.0
        - -3046886912.0
        - -2141980672.0
        - 23502266368.0
        - -2234296320.0
        - 23502266368.0
        - -2375537664.0
        - 6209150976.0
        - 23502266368.0
        - 25823911936.0
        - 23502266368.0
        - 6209150976.0
        - -2347540480.0
        - -1045782528.0
        - -1895745536.0
        - -1751293952.0
        - -2234296320.0
        - -3046886912.0
        - -2385389568.0
        - -2397958144.0
        - -2385397248.0
        - -2375537664.0
        - -2276847616.0
        - -1896511488.0
        - -1719463936.0
        - -2385389568.0
        - -2397958144.0
    num_agent_steps_sampled: 984623
    num_agent_steps_trained: 143104
    num_steps_sampled: 984720
    num_steps_trained: 71552
    num_steps_trained_this_iter: 32
    num_target_updates: 1118
  iterations_since_restore: 299
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 5.65
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.5031055900621118
    player_1: 0.5031055900621118
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08062708360330136
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6179040078484787
    mean_inference_ms: 1.1454066115945132
    mean_raw_obs_processing_ms: 0.36964858988998817
  time_since_restore: 372.8454065322876
  time_this_iter_s: 1.343384027481079
  time_total_s: 372.8454065322876
  timers:
    learn_throughput: 1616.625
    learn_time_ms: 19.794
    update_time_ms: 21.407
  timestamp: 1650591353
  timesteps_since_restore: 9568
  timesteps_this_iter: 32
  timesteps_total: 984720
  training_iteration: 299
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:35:54 (running for 00:06:54.46)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    300 |          374.226 | 988680 |        0 |                    0 |                    0 |            16.2389 |
+-----------------------+----------+-------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 997818
  custom_metrics: {}
  date: 2022-04-22_01-35-58
  done: false
  episode_len_mean: 16.53503184713376
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 157
  episodes_total: 62919
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 997480
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 153480864.0
          max_q: 40283537408.0
          mean_q: 19675179008.0
          min_q: 4200354560.0
        mean_td_error: 5262649344.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 27891324928.0
        - -2238877696.0
        - -3005761536.0
        - 27891324928.0
        - -3005761536.0
        - -399704064.0
        - -2033935360.0
        - -1667643392.0
        - -2753825792.0
        - 27891324928.0
        - 27891324928.0
        - -2752944128.0
        - -2045590528.0
        - 27891324928.0
        - -1153183744.0
        - -1478330368.0
        - 27891324928.0
        - -1465962496.0
        - 27891324928.0
        - -3005761536.0
        - -2753394688.0
        - -3202465536.0
        - -2428997376.0
        - -2238877696.0
        - -3202465536.0
        - -2753825792.0
        - -1478330368.0
        - -2752944128.0
        - -1465962496.0
        - -2238797824.0
        - -3202465536.0
        - 27891324928.0
    num_agent_steps_sampled: 997818
    num_agent_steps_trained: 145024
    num_steps_sampled: 997920
    num_steps_trained: 72512
    num_steps_trained_this_iter: 32
    num_target_updates: 1133
  iterations_since_restore: 303
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.9
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.3821656050955414
    player_1: 0.3821656050955414
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08086767999390514
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6199032721327301
    mean_inference_ms: 1.1490945465269757
    mean_raw_obs_processing_ms: 0.3710776662590641
  time_since_restore: 377.87947845458984
  time_this_iter_s: 0.9652993679046631
  time_total_s: 377.87947845458984
  timers:
    learn_throughput: 1528.027
    learn_time_ms: 20.942
    update_time_ms: 20.104
  timestamp: 1650591358
  timesteps_since_restore: 9696
  timesteps_this_iter: 32
  timesteps_total: 997920
  training_iteration: 303
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:36:00 (running for 00:06:59.76)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    304 |          379.298 | 1001880 |        0 |                    0 |                    0 |            15.7435 |
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 1011016
  custom_metrics: {}
  date: 2022-04-22_01-36-04
  done: false
  episode_len_mean: 14.423220973782772
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 267
  episodes_total: 63796
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 1010680
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 2097951.75
          max_q: 44341460992.0
          mean_q: 19073392640.0
          min_q: 4611738624.0
        mean_td_error: 7579376128.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 29967607808.0
        - -3323469824.0
        - -3578859520.0
        - 29967607808.0
        - 29967607808.0
        - 29967607808.0
        - -3208466432.0
        - -3208466432.0
        - -3578859520.0
        - -1790646272.0
        - -3578859520.0
        - -2452451840.0
        - -2503195648.0
        - -3323469824.0
        - 29967607808.0
        - 609267712.0
        - -3208466432.0
        - 29967607808.0
        - 29967607808.0
        - -3578859520.0
        - -1790646272.0
        - -761401344.0
        - 29967607808.0
        - -2452451840.0
        - -3208466432.0
        - -1810951168.0
        - -3894063104.0
        - 609267712.0
        - 29967607808.0
        - -3208466432.0
        - 29967607808.0
        - -3894063104.0
    num_agent_steps_sampled: 1011016
    num_agent_steps_trained: 146944
    num_steps_sampled: 1011120
    num_steps_trained: 73472
    num_steps_trained_this_iter: 32
    num_target_updates: 1148
  iterations_since_restore: 307
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.8
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.41198501872659177
    player_1: 0.41198501872659177
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08117725165375374
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6215169798634989
    mean_inference_ms: 1.15121899765888
    mean_raw_obs_processing_ms: 0.37023295363902853
  time_since_restore: 382.9910192489624
  time_this_iter_s: 1.4043512344360352
  time_total_s: 382.9910192489624
  timers:
    learn_throughput: 1521.576
    learn_time_ms: 21.031
    update_time_ms: 21.117
  timestamp: 1650591364
  timesteps_since_restore: 9824
  timesteps_this_iter: 32
  timesteps_total: 1011120
  training_iteration: 307
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:36:06 (running for 00:07:06.04)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    309 |           385.29 | 1016400 |        0 |                    0 |                    0 |            16.5398 |
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 1026857
  custom_metrics: {}
  date: 2022-04-22_01-36-10
  done: false
  episode_len_mean: 15.224806201550388
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 258
  episodes_total: 64821
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 1026520
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 7225156.0
          max_q: 50121072640.0
          mean_q: 21424302080.0
          min_q: 4998244352.0
        mean_td_error: 13346679808.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -2624244736.0
        - 32015253504.0
        - -1725784064.0
        - -1747310592.0
        - -2125390848.0
        - 32015253504.0
        - 32013189120.0
        - -2710595584.0
        - -3894627328.0
        - 32013189120.0
        - 32015253504.0
        - -3553519616.0
        - 4186894592.0
        - -1725626368.0
        - 32015253504.0
        - -3553519616.0
        - -1725784064.0
        - 32015253504.0
        - -2624244736.0
        - 32015253504.0
        - 32013189120.0
        - 32015253504.0
        - 32013189120.0
        - 4186894592.0
        - -2187913216.0
        - 32013189120.0
        - -2187041792.0
        - 32013189120.0
        - 4186894592.0
        - -1747310592.0
        - 32013189120.0
        - 466903040.0
    num_agent_steps_sampled: 1026857
    num_agent_steps_trained: 149248
    num_steps_sampled: 1026960
    num_steps_trained: 74624
    num_steps_trained_this_iter: 32
    num_target_updates: 1166
  iterations_since_restore: 312
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 7.066666666666667
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.17829457364341086
    player_1: 0.17829457364341086
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08081784161537633
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.618275015381075
    mean_inference_ms: 1.1479479124949001
    mean_raw_obs_processing_ms: 0.36748871544051864
  time_since_restore: 389.40155482292175
  time_this_iter_s: 1.796767234802246
  time_total_s: 389.40155482292175
  timers:
    learn_throughput: 1600.337
    learn_time_ms: 19.996
    update_time_ms: 20.618
  timestamp: 1650591370
  timesteps_since_restore: 9984
  timesteps_this_iter: 32
  timesteps_total: 1026960
  training_iteration: 312
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:36:13 (running for 00:07:12.94)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    313 |          390.739 | 1030920 |        0 |                    0 |                    0 |            14.6434 |
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 1040063
  custom_metrics: {}
  date: 2022-04-22_01-36-17
  done: false
  episode_len_mean: 16.233201581027668
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 253
  episodes_total: 65676
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 1039720
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 6024101.0
          max_q: 50146803712.0
          mean_q: 22767796224.0
          min_q: 3722358784.0
        mean_td_error: 7171034112.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 31316588544.0
        - -4974647296.0
        - -1917520896.0
        - -4622286848.0
        - -4622286848.0
        - 1054769920.0
        - 31316588544.0
        - 31327862784.0
        - -1916591104.0
        - -4122736640.0
        - -4974647296.0
        - 1434451968.0
        - -4008980480.0
        - 1422958592.0
        - -109456384.0
        - 31327862784.0
        - -109456384.0
        - -2227206144.0
        - 31316588544.0
        - -4974647296.0
        - 1434451968.0
        - 31327862784.0
        - -1838701568.0
        - 31327862784.0
        - -1917520896.0
        - -4122736640.0
        - -4008980480.0
        - -4122736640.0
        - 31327862784.0
        - -4622286848.0
        - 31327862784.0
        - 1422958592.0
    num_agent_steps_sampled: 1040063
    num_agent_steps_trained: 151168
    num_steps_sampled: 1040160
    num_steps_trained: 75584
    num_steps_trained_this_iter: 32
    num_target_updates: 1181
  iterations_since_restore: 316
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.45
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.2845849802371542
    player_1: 0.2845849802371542
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08064388689279688
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6176614703696525
    mean_inference_ms: 1.1455163898965162
    mean_raw_obs_processing_ms: 0.36771933332110934
  time_since_restore: 394.2846665382385
  time_this_iter_s: 1.3180689811706543
  time_total_s: 394.2846665382385
  timers:
    learn_throughput: 1633.533
    learn_time_ms: 19.589
    update_time_ms: 19.52
  timestamp: 1650591377
  timesteps_since_restore: 10112
  timesteps_this_iter: 32
  timesteps_total: 1040160
  training_iteration: 316
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:36:18 (running for 00:07:18.01)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    317 |          395.588 | 1044120 |        0 |                    0 |                    0 |            16.0952 |
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 1054573
  custom_metrics: {}
  date: 2022-04-22_01-36-22
  done: false
  episode_len_mean: 15.219607843137254
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 255
  episodes_total: 66578
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 1054680
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 5163945.5
          max_q: 49425448960.0
          mean_q: 21207427072.0
          min_q: 6959854592.0
        mean_td_error: 4681962496.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - 30829584384.0
        - 30829584384.0
        - -2099273728.0
        - -1207199744.0
        - -1810092032.0
        - 6959854592.0
        - -3683077120.0
        - -5489719296.0
        - -4618891264.0
        - -5489719296.0
        - -4129416192.0
        - 30829584384.0
        - -5489719296.0
        - -5489719296.0
        - -1207199744.0
        - -1728316416.0
        - 30829584384.0
        - -4980987904.0
        - -4514025472.0
        - 6959854592.0
        - 30829584384.0
        - -4980987904.0
        - 30829584384.0
        - -5489719296.0
        - -1810092032.0
        - -4618891264.0
        - -4618891264.0
        - 1692184576.0
        - -1812707328.0
        - -1813511168.0
        - -4514025472.0
        - 30829584384.0
    num_agent_steps_sampled: 1054573
    num_agent_steps_trained: 153280
    num_steps_sampled: 1054680
    num_steps_trained: 76640
    num_steps_trained_this_iter: 32
    num_target_updates: 1198
  iterations_since_restore: 320
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.3
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.41568627450980394
    player_1: 0.41568627450980394
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.0807212131384307
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6186681398302554
    mean_inference_ms: 1.146651670722203
    mean_raw_obs_processing_ms: 0.36969706585392537
  time_since_restore: 399.60165882110596
  time_this_iter_s: 1.3416967391967773
  time_total_s: 399.60165882110596
  timers:
    learn_throughput: 1628.68
    learn_time_ms: 19.648
    update_time_ms: 21.039
  timestamp: 1650591382
  timesteps_since_restore: 10240
  timesteps_this_iter: 32
  timesteps_total: 1054680
  training_iteration: 320
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:36:24 (running for 00:07:23.62)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    321 |          400.953 | 1057320 |        0 |                    0 |                    0 |             15.407 |
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
  agent_timesteps_total: 1067777
  custom_metrics: {}
  date: 2022-04-22_01-36-28
  done: false
  episode_len_mean: 15.879518072289157
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 166
  episodes_total: 67391
  experiment_id: d51450b76a2148039ce72ff92cd7b99b
  hostname: instance-20220419-2114
  info:
    last_target_update_ts: 1067880
    learner:
      player_0:
        custom_metrics: {}
        learner_stats:
          allreduce_latency: 0.0
          cur_lr: 0.0005
          grad_gnorm: 8048107.5
          max_q: 51286523904.0
          mean_q: 14225448960.0
          min_q: 1794122880.0
        mean_td_error: -3038281216.0
        model: {}
        num_agent_steps_trained: 32
        td_error:
        - -4399601664.0
        - -5253660672.0
        - -3330280960.0
        - -3714426880.0
        - -4095449088.0
        - -4691412480.0
        - -3582992384.0
        - -4095449088.0
        - -4691412480.0
        - -4095449088.0
        - -2038187008.0
        - -3330280960.0
        - -5253660672.0
        - -3330280960.0
        - -5253660672.0
        - -4691412480.0
        - -3714426880.0
        - -4399601664.0
        - -2035442688.0
        - 205813760.0
        - 3728929280.0
        - 1186254848.0
        - -3582992384.0
        - -442679296.0
        - -4399601664.0
        - -2038187008.0
        - -2035442688.0
        - -2038187008.0
        - -2572123136.0
        - -2572123136.0
        - -2572123136.0
        - -4095449088.0
    num_agent_steps_sampled: 1067777
    num_agent_steps_trained: 155200
    num_steps_sampled: 1067880
    num_steps_trained: 77600
    num_steps_trained_this_iter: 32
    num_target_updates: 1213
  iterations_since_restore: 324
  node_ip: 10.0.0.177
  num_healthy_workers: 110
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 8.399999999999999
    ram_util_percent: 20.8
  pid: 612604
  policy_reward_max:
    player_0: 1.0
    player_1: 1.0
  policy_reward_mean:
    player_0: -0.39759036144578314
    player_1: 0.39759036144578314
  policy_reward_min:
    player_0: -1.0
    player_1: -1.0
  sampler_perf:
    mean_action_processing_ms: 0.08058941882769678
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.6169888690295476
    mean_inference_ms: 1.1448698829617827
    mean_raw_obs_processing_ms: 0.36663673688626064
  time_since_restore: 405.0312054157257
  time_this_iter_s: 1.3807740211486816
  time_total_s: 405.0312054157257
  timers:
    learn_throughput: 1588.928
    learn_time_ms: 20.139
    update_time_ms: 20.455
  timestamp: 1650591388
  timesteps_since_restore: 10368
  timesteps_this_iter: 32
  timesteps_total: 1067880
  training_iteration: 324
  trial_id: '96499_00000'
  warmup_time: 3.954873561859131
  
== Status ==
Current time: 2022-04-22 01:36:29 (running for 00:07:29.29)
Memory usage on this node: 26.0/125.3 GiB
Using FIFO scheduling algorithm.
Resources requested: 111.0/128 CPUs, 0/0 GPUs, 0.0/77.15 GiB heap, 0.0/37.06 GiB objects
Result logdir: /home/opc/ray-results/dqn shogi
Number of trials: 1/1 (1 RUNNING)
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name            | status   | loc               |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| DQN_shogi_96499_00000 | RUNNING  | 10.0.0.177:612604 |    325 |          406.391 | 1071840 |        0 |                    0 |                    0 |            16.7906 |
+-----------------------+----------+-------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for DQN_shogi_96499_00000:
